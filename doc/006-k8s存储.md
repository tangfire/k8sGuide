# å­˜å‚¨ - ç»™æ•°æ®ä¸€ä¸ªå¯é çš„å®¶

## 01. å­˜å‚¨åˆ†ç±»

![123](../img/img_123.png)



## 02. configMap

é…ç½®ä¿¡æ¯çš„ä¿å­˜æ–¹å¼

### configMap - æ¨¡å‹

![124](../img/img_124.png)


### configMap - å®šä¹‰

![125](../img/img_125.png)


### å¤šä¸ªæœåŠ¡ä¹‹é—´çš„æ–‡ä»¶ï¼ˆå¦‚é…ç½®æ–‡ä»¶ã€é™æ€èµ„æºã€æ•°æ®æ–‡ä»¶ç­‰ï¼‰ä¿æŒä¸€è‡´æ€§çš„ä¸¤ç§æ€æƒ³ï¼šå…±äº«å’Œæ³¨å…¥

![126](../img/img_126.png)


![127](../img/img_127.png)

- å¤šä¸ªä¸åŒçš„æœåŠ¡å†…éƒ¨çš„æ–‡ä»¶è¾¾åˆ°ä¸€è‡´
  - å…±äº«
    - æ¯ä¸€æ¬¡åœ¨è¯»å–æ–‡ä»¶çš„æ—¶å€™ï¼Œéƒ½ä¼šå‘ç”Ÿç½‘ç»œIO
  - æ³¨å…¥  configmap
    - ä¸€æ¬¡æ³¨å…¥åï¼Œå¤šæ¬¡è¯»å–ä¸å†æ¶ˆè€—ç½‘ç»œIO



---

åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿæˆ–å¾®æœåŠ¡æ¶æ„ä¸­ï¼Œç¡®ä¿å¤šä¸ªæœåŠ¡ä¹‹é—´çš„æ–‡ä»¶ï¼ˆå¦‚é…ç½®æ–‡ä»¶ã€é™æ€èµ„æºã€æ•°æ®æ–‡ä»¶ç­‰ï¼‰ä¿æŒä¸€è‡´æ€§æ˜¯ä¸€ä¸ªå¸¸è§éœ€æ±‚ã€‚ä»¥ä¸‹æ˜¯ä¸¤ç§æ ¸å¿ƒæ€æƒ³ï¼š**å…±äº«ï¼ˆSharingï¼‰** å’Œ **æ³¨å…¥ï¼ˆInjectionï¼‰**ï¼Œåˆ†åˆ«é€šè¿‡ä¸åŒçš„æœºåˆ¶å®ç°æ–‡ä»¶ä¸€è‡´æ€§ã€‚

---

## 1. **å…±äº«ï¼ˆSharingï¼‰æ€æƒ³**
**æ ¸å¿ƒé€»è¾‘**ï¼šå¤šä¸ªæœåŠ¡é€šè¿‡è®¿é—®åŒä¸€ä¸ªå…±äº«å­˜å‚¨æˆ–ä¸­é—´åª’ä»‹æ¥è·å–æ–‡ä»¶ï¼Œç¡®ä¿æ‰€æœ‰æœåŠ¡è¯»å–çš„å†…å®¹å§‹ç»ˆä¸€è‡´ã€‚  
**é€‚ç”¨åœºæ™¯**ï¼šæ–‡ä»¶è¾ƒå¤§ã€æ›´æ–°é¢‘ç‡ä½ã€éœ€è¦å¤šæœåŠ¡å®æ—¶åŒæ­¥çš„åœºæ™¯ï¼ˆå¦‚é…ç½®æ–‡ä»¶ã€é™æ€èµ„æºï¼‰ã€‚

### å®ç°æ–¹å¼ï¼š
#### ï¼ˆ1ï¼‰**å…±äº«å­˜å‚¨å·ï¼ˆVolumeï¼‰**
- **å·¥å…·**ï¼šKubernetes çš„ `PersistentVolume (PV)`ã€`PersistentVolumeClaim (PVC)`ï¼Œæˆ–äº‘å­˜å‚¨ï¼ˆå¦‚ AWS S3ã€NFSï¼‰ã€‚
- **åŸç†**ï¼šå°†æ–‡ä»¶å­˜å‚¨åœ¨å…±äº«å·ä¸­ï¼Œå¤šä¸ªæœåŠ¡æŒ‚è½½åŒä¸€å·ï¼Œç›´æ¥è¯»å–åŒä¸€ä»½æ–‡ä»¶ã€‚
- **ç¤ºä¾‹**ï¼š
  ```yaml
  # Kubernetes DeploymentæŒ‚è½½å…±äº«PVC
  volumes:
    - name: shared-config
      persistentVolumeClaim:
        claimName: my-pvc  # å¤šä¸ªPodå…±ç”¨åŒä¸€ä¸ªPVC
  ```

#### ï¼ˆ2ï¼‰**åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ**
- **å·¥å…·**ï¼šHDFSã€Cephã€GlusterFSã€‚
- **åŸç†**ï¼šæ–‡ä»¶åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­å…¨å±€å¯è§ï¼ŒæœåŠ¡é€šè¿‡ç»Ÿä¸€æ¥å£è®¿é—®ã€‚

#### ï¼ˆ3ï¼‰**ä¸­é—´ä»¶åŒæ­¥**
- **å·¥å…·**ï¼šæ•°æ®åº“ï¼ˆå¦‚ MySQLï¼‰ã€é…ç½®ä¸­å¿ƒï¼ˆå¦‚ Apolloã€Nacosï¼‰ã€‚
- **åŸç†**ï¼šå°†æ–‡ä»¶å†…å®¹å­˜å…¥æ•°æ®åº“æˆ–é…ç½®ä¸­å¿ƒï¼ŒæœåŠ¡å®šæœŸæ‹‰å–æˆ–ç›‘å¬å˜æ›´ã€‚

### ä¼˜ç¼ºç‚¹ï¼š
| **ä¼˜ç‚¹**                     | **ç¼ºç‚¹**                     |
|------------------------------|------------------------------|
| æ–‡ä»¶å•ç‚¹å­˜å‚¨ï¼Œå¼ºä¸€è‡´æ€§       | å…±äº«å­˜å‚¨å¯èƒ½æˆä¸ºæ€§èƒ½ç“¶é¢ˆ     |
| æ›´æ–°æ—¶åªéœ€ä¿®æ”¹ä¸€æ¬¡           | éœ€è¦å¤„ç†å¹¶å‘è¯»å†™å†²çª         |
| é€‚åˆå¤§æ–‡ä»¶æˆ–é¢‘ç¹è¯»åœºæ™¯       | ä¾èµ–å¤–éƒ¨å­˜å‚¨ç³»ç»Ÿï¼Œå¤æ‚åº¦é«˜   |

---

## 2. **æ³¨å…¥ï¼ˆInjectionï¼‰æ€æƒ³**
**æ ¸å¿ƒé€»è¾‘**ï¼šå°†æ–‡ä»¶å†…å®¹é€šè¿‡æŸç§æœºåˆ¶ä¸»åŠ¨åˆ†å‘åˆ°å„ä¸ªæœåŠ¡ä¸­ï¼ŒæœåŠ¡æœ¬åœ°æŒæœ‰æ–‡ä»¶çš„å‰¯æœ¬ã€‚  
**é€‚ç”¨åœºæ™¯**ï¼šæ–‡ä»¶è¾ƒå°ã€éœ€è¦ç‰ˆæœ¬æ§åˆ¶ã€æˆ–æœåŠ¡éœ€ç¦»çº¿è¿è¡Œçš„åœºæ™¯ï¼ˆå¦‚å®¹å™¨å¯åŠ¨é…ç½®ï¼‰ã€‚

### å®ç°æ–¹å¼ï¼š
#### ï¼ˆ1ï¼‰**é…ç½®å³ä»£ç ï¼ˆConfiguration as Codeï¼‰**
- **å·¥å…·**ï¼šGit ä»“åº“ + CI/CDï¼ˆå¦‚ Jenkinsã€GitLab CIï¼‰ã€‚
- **åŸç†**ï¼šæ–‡ä»¶å­˜å‚¨åœ¨ä»£ç åº“ä¸­ï¼ŒæœåŠ¡éƒ¨ç½²æ—¶é€šè¿‡æµæ°´çº¿å°†æ–‡ä»¶æ‰“åŒ…åˆ°å®¹å™¨é•œåƒæˆ–ç›´æ¥æ³¨å…¥ç¯å¢ƒå˜é‡ã€‚
- **ç¤ºä¾‹**ï¼š
  ```dockerfile
  # Dockerfileä¸­å¤åˆ¶é…ç½®æ–‡ä»¶
  COPY ./configs/app.conf /etc/service/app.conf
  ```

#### ï¼ˆ2ï¼‰**é…ç½®ç®¡ç†å·¥å…·**
- **å·¥å…·**ï¼šAnsibleã€Chefã€Puppetã€‚
- **åŸç†**ï¼šå·¥å…·å°†æ–‡ä»¶æ¨é€åˆ°å„ä¸ªæœåŠ¡çš„æœ¬åœ°ç›®å½•ã€‚

#### ï¼ˆ3ï¼‰**å®¹å™¨å¯åŠ¨æ—¶æ³¨å…¥**
- **å·¥å…·**ï¼šKubernetes çš„ `ConfigMap`ã€`Secret`ã€‚
- **åŸç†**ï¼šå°†æ–‡ä»¶å†…å®¹å®šä¹‰ä¸º `ConfigMap`ï¼ŒæŒ‚è½½ä¸ºå®¹å™¨çš„å·æˆ–ç¯å¢ƒå˜é‡ã€‚
- **ç¤ºä¾‹**ï¼š
  ```yaml
  # å°†ConfigMapæŒ‚è½½ä¸ºPodçš„æ–‡ä»¶
  volumes:
    - name: config-volume
      configMap:
        name: app-config
  ```

### ä¼˜ç¼ºç‚¹ï¼š
| **ä¼˜ç‚¹**                     | **ç¼ºç‚¹**                     |
|------------------------------|------------------------------|
| æœåŠ¡æœ¬åœ°è®¿é—®æ–‡ä»¶ï¼Œæ€§èƒ½é«˜     | æ›´æ–°éœ€é‡æ–°åˆ†å‘ï¼Œå¯èƒ½å»¶è¿Ÿ     |
| æ— å…±äº«ä¾èµ–ï¼Œéƒ¨ç½²æ›´ç®€å•       | å¤šå‰¯æœ¬é—´å¯èƒ½å­˜åœ¨çŸ­æš‚ä¸ä¸€è‡´   |
| é€‚åˆæ•æ„Ÿé…ç½®ï¼ˆå¦‚å¯†é’¥ï¼‰       | æ–‡ä»¶ç‰ˆæœ¬ç®¡ç†éœ€é¢å¤–è®¾è®¡       |

---

## **å¯¹æ¯”ä¸é€‰å‹å»ºè®®**
| **ç»´åº¦**         | **å…±äº«ï¼ˆSharingï¼‰**          | **æ³¨å…¥ï¼ˆInjectionï¼‰**        |
|------------------|-----------------------------|-----------------------------|
| **ä¸€è‡´æ€§å¼ºåº¦**   | å¼ºä¸€è‡´æ€§ï¼ˆå®æ—¶åŒæ­¥ï¼‰        | æœ€ç»ˆä¸€è‡´æ€§ï¼ˆéœ€åˆ†å‘æ—¶é—´ï¼‰     |
| **æ€§èƒ½å½±å“**     | ä¾èµ–å…±äº«å­˜å‚¨æ€§èƒ½            | æœ¬åœ°è¯»å–ï¼Œæ€§èƒ½é«˜            |
| **å¤æ‚åº¦**       | éœ€ç»´æŠ¤å…±äº«å­˜å‚¨ç³»ç»Ÿ          | éœ€è®¾è®¡åˆ†å‘æœºåˆ¶              |
| **é€‚ç”¨åœºæ™¯**     | å¤šæœåŠ¡å®æ—¶è¯»å†™å¤§æ–‡ä»¶        | æ•æ„Ÿé…ç½®æˆ–ç¦»çº¿æœåŠ¡          |

### **å®é™…ç»„åˆä½¿ç”¨æ¡ˆä¾‹**
- **Kubernetes æœ€ä½³å®è·µ**ï¼š
    - ç”¨ `ConfigMap`ï¼ˆæ³¨å…¥ï¼‰ç®¡ç†é…ç½®æ–‡ä»¶ï¼Œé€šè¿‡å·æŒ‚è½½åˆ°å¤šä¸ª Podã€‚
    - ç”¨ `PV/PVC`ï¼ˆå…±äº«ï¼‰å­˜å‚¨æ—¥å¿—æˆ–å¤§æ•°æ®æ–‡ä»¶ã€‚
- **æ··åˆæ¶æ„**ï¼š
    - æ•°æ®åº“è¿æ¥å­—ç¬¦ä¸²é€šè¿‡ `Secret`ï¼ˆæ³¨å…¥ï¼‰åˆ†å‘ï¼Œé™æ€èµ„æºé€šè¿‡ CDNï¼ˆå…±äº«ï¼‰è®¿é—®ã€‚

---

## **æ€»ç»“**
- **é€‰æ‹©å…±äº«**ï¼šå½“éœ€è¦å¼ºä¸€è‡´æ€§ã€æ–‡ä»¶è¾ƒå¤§æˆ–å¤šæœåŠ¡é¢‘ç¹è¯»å†™æ—¶ï¼ˆå¦‚å…±äº«æ—¥å¿—å­˜å‚¨ï¼‰ã€‚
- **é€‰æ‹©æ³¨å…¥**ï¼šå½“éœ€è¦å¿«é€Ÿå¯åŠ¨ã€éš”ç¦»æ€§é«˜æˆ–é…ç½®æ•æ„Ÿæ—¶ï¼ˆå¦‚å¾®æœåŠ¡é…ç½®ï¼‰ã€‚

ä¸¤ç§æ€æƒ³å¹¶éäº’æ–¥ï¼Œå®é™…ç³»ç»Ÿä¸­å¸¸ç»“åˆä½¿ç”¨ï¼Œä¾‹å¦‚ç”¨å…±äº«å­˜å‚¨å­˜æ”¾å¤§æ•°æ®ï¼ŒåŒæ—¶ç”¨ ConfigMap æ³¨å…¥å…³é”®é…ç½®ã€‚



---


### **é€šä¿—ç‰ˆè§£é‡Šï¼šå…±äº« vs æ³¨å…¥**

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ å’Œå‡ ä¸ªåŒäº‹ï¼ˆä»£è¡¨ä¸åŒçš„æœåŠ¡ï¼‰éœ€è¦ä¸€èµ·å®Œæˆä¸€ä¸ªé¡¹ç›®ï¼Œè€Œé¡¹ç›®èµ„æ–™ï¼ˆæ–‡ä»¶ï¼‰éœ€è¦ä¿æŒä¸€è‡´ã€‚æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥åšåˆ°ï¼š

---

### **1. å…±äº«ï¼ˆSharingï¼‰â€”â€”å¤§å®¶ä¸€èµ·çœ‹åŒä¸€ä»½èµ„æ–™**
**åœºæ™¯**ï¼š
- ä½ ä»¬æ‰€æœ‰äººéƒ½åœ¨ä¸€ä¸ªåŠå…¬å®¤é‡Œï¼Œèµ„æ–™æ”¾åœ¨åŠå…¬å®¤ä¸­å¤®çš„ä¸€ä¸ªå…±äº«æ–‡ä»¶å¤¹é‡Œã€‚
- è°éœ€è¦çœ‹èµ„æ–™ï¼Œå°±ç›´æ¥å»æ–‡ä»¶å¤¹é‡Œæ‹¿ã€‚
- å¦‚æœæœ‰äººæ›´æ–°äº†èµ„æ–™ï¼Œå…¶ä»–äººç«‹åˆ»å°±èƒ½çœ‹åˆ°æœ€æ–°ç‰ˆæœ¬ã€‚

**ä¾‹å­**ï¼š
- **äº‘ç›˜å…±äº«**ï¼šæ¯”å¦‚ç”¨ç™¾åº¦ç½‘ç›˜æˆ–Google Driveå­˜æ–‡ä»¶ï¼Œæ‰€æœ‰äººè®¿é—®åŒä¸€ä¸ªé“¾æ¥ï¼Œæ–‡ä»¶ä¸€æ”¹å¤§å®¶éƒ½èƒ½çœ‹åˆ°ã€‚
- **Kuberneteså…±äº«å­˜å‚¨**ï¼šå¤šä¸ªæœåŠ¡æŒ‚è½½åŒä¸€ä¸ªç£ç›˜ï¼ˆæ¯”å¦‚NFSï¼‰ï¼Œæ–‡ä»¶æ”¹äº†æ‰€æœ‰æœåŠ¡éƒ½èƒ½è¯»åˆ°ã€‚

**ä¼˜ç‚¹**ï¼š
- æ–‡ä»¶åªæœ‰ä¸€ä»½ï¼Œä¸ä¼šä¹±ï¼ˆå¼ºä¸€è‡´æ€§ï¼‰ã€‚
- æ”¹ä¸€æ¬¡ï¼Œæ‰€æœ‰äººé©¬ä¸Šç”Ÿæ•ˆã€‚

**ç¼ºç‚¹**ï¼š
- å¦‚æœå…±äº«æ–‡ä»¶å¤¹æŒ‚äº†ï¼ˆæ¯”å¦‚ç½‘ç›˜å´©äº†ï¼‰ï¼Œæ‰€æœ‰äººéƒ½æ²¡æ³•å¹²æ´»ã€‚
- å¦‚æœå¾ˆå¤šäººåŒæ—¶æ”¹æ–‡ä»¶ï¼Œå¯èƒ½ä¼šå†²çªï¼ˆæ¯”å¦‚ä¸¤ä¸ªäººåŒæ—¶æ”¹åŒä¸€è¡Œï¼‰ã€‚

---

### **2. æ³¨å…¥ï¼ˆInjectionï¼‰â€”â€”æ¯äººå‘ä¸€ä»½èµ„æ–™å‰¯æœ¬**
**åœºæ™¯**ï¼š
- ä½ ä»¬ä¸åœ¨ä¸€ä¸ªåŠå…¬å®¤ï¼Œæ²¡æ³•å®æ—¶å…±äº«æ–‡ä»¶ã€‚
- é¢†å¯¼ï¼ˆç³»ç»Ÿç®¡ç†å‘˜ï¼‰æŠŠèµ„æ–™æ‰“å°å¥½ï¼Œæ¯äººå‘ä¸€ä»½ï¼Œæ”¾å„è‡ªæ¡Œä¸Šã€‚
- å¦‚æœèµ„æ–™æœ‰æ›´æ–°ï¼Œé¢†å¯¼å¾—é‡æ–°æ‰“å°ï¼Œå†å‘ä¸€éï¼ˆå¯èƒ½æœ‰ç‚¹å»¶è¿Ÿï¼‰ã€‚

**ä¾‹å­**ï¼š
- **é…ç½®æ–‡ä»¶æ‰“åŒ…è¿›è½¯ä»¶**ï¼šæ¯”å¦‚APPçš„é…ç½®ç›´æ¥å†™åœ¨ä»£ç é‡Œï¼Œæ›´æ–°æ—¶è¦é‡æ–°å‘å¸ƒæ–°ç‰ˆæœ¬ã€‚
- **Kubernetes ConfigMap**ï¼šæŠŠé…ç½®æ–‡ä»¶â€œæ³¨å…¥â€åˆ°æ¯ä¸ªæœåŠ¡é‡Œï¼Œæ”¹é…ç½®åè¦é‡å¯æœåŠ¡æ‰èƒ½ç”Ÿæ•ˆã€‚

**ä¼˜ç‚¹**ï¼š
- æ¯äººæœ‰è‡ªå·±çš„æ–‡ä»¶ï¼Œä¸ä¾èµ–åˆ«äººï¼ˆé«˜å¯ç”¨ï¼‰ã€‚
- é€‚åˆæ•æ„Ÿä¿¡æ¯ï¼ˆæ¯”å¦‚å¯†ç ï¼‰ï¼Œå› ä¸ºä¸ç”¨å…±äº«å­˜å‚¨ã€‚

**ç¼ºç‚¹**ï¼š
- å¦‚æœæ–‡ä»¶æ›´æ–°äº†ï¼Œä¸èƒ½é©¬ä¸ŠåŒæ­¥ï¼ˆå¾—ç­‰é¢†å¯¼é‡æ–°å‘ï¼‰ã€‚
- å¦‚æœæ¯äººæ‰‹é‡Œçš„ç‰ˆæœ¬ä¸ä¸€æ ·ï¼Œå¯èƒ½ä¼šä¹±ï¼ˆæœ€ç»ˆä¸€è‡´æ€§ï¼‰ã€‚

---

### **ç°å®ä¸­çš„ä¾‹å­**
- **å…±äº«ï¼ˆSharingï¼‰**
  - å…¬å¸ç”¨ **Excel åœ¨çº¿åä½œ**ï¼ˆæ¯”å¦‚è…¾è®¯æ–‡æ¡£ï¼‰ï¼Œæ‰€æœ‰äººç¼–è¾‘åŒä¸€ä»½è¡¨æ ¼ã€‚
  - é£é™©ï¼šå¦‚æœè…¾è®¯æ–‡æ¡£å´©äº†ï¼Œæ‰€æœ‰äººéƒ½æ²¡æ³•å·¥ä½œã€‚

- **æ³¨å…¥ï¼ˆInjectionï¼‰**
  - å…¬å¸å‘ **PDF æ–‡ä»¶**ç»™æ¯ä¸ªå‘˜å·¥ï¼Œå¦‚æœæ›´æ–°äº†å¾—é‡æ–°å‘é‚®ä»¶ã€‚
  - é£é™©ï¼šæœ‰äººå¯èƒ½æ²¡æ”¶åˆ°æœ€æ–°ç‰ˆï¼Œè¿˜åœ¨ç”¨æ—§æ–‡ä»¶ã€‚

---

### **æ€ä¹ˆé€‰ï¼Ÿ**
| **æ–¹å¼** | **é€‚åˆåœºæ™¯** | **ä¸é€‚ç”¨åœºæ™¯** |
|----------|------------|--------------|
| **å…±äº«** | éœ€è¦å®æ—¶åŒæ­¥ï¼ˆå¦‚å¤šäººç¼–è¾‘æ–‡æ¡£ï¼‰ | æ–‡ä»¶å¾ˆå¤§ã€å…±äº«å­˜å‚¨ä¸å¯é  |
| **æ³¨å…¥** | éœ€è¦ç‹¬ç«‹è¿è¡Œï¼ˆå¦‚APPé…ç½®ï¼‰ | è¦æ±‚å¼ºä¸€è‡´æ€§ï¼ˆä¸èƒ½å®¹å¿å»¶è¿Ÿï¼‰ |

**å®é™…åº”ç”¨**ï¼š
- **å¾®æœåŠ¡é…ç½®**ï¼šç”¨ **æ³¨å…¥**ï¼ˆConfigMapï¼‰ï¼Œå› ä¸ºæ¯ä¸ªæœåŠ¡è¦ç‹¬ç«‹è¿è¡Œã€‚
- **æ—¥å¿—å­˜å‚¨**ï¼šç”¨ **å…±äº«**ï¼ˆNFSï¼‰ï¼Œå› ä¸ºæ—¥å¿—è¦é›†ä¸­ç®¡ç†ã€‚

ç®€å•æ¥è¯´ï¼š
- **å…±äº«** = å¤§å®¶ä¸€èµ·çœ‹åŒä¸€æœ¬ä¹¦ï¼ˆå®æ—¶ï¼Œä½†ä¾èµ–ä¹¦ä¸èƒ½ä¸¢ï¼‰ã€‚
- **æ³¨å…¥** = æ¯äººå‘ä¸€æœ¬ï¼ˆç‹¬ç«‹ï¼Œä½†æ›´æ–°æ…¢ï¼‰ã€‚

æ ¹æ®ä½ çš„éœ€æ±‚é€‰å°±è¡Œï¼ ğŸ˜Š

---


### configMap - åˆ›å»º

- `kubectl create configmap game-config --from-file=fire.file`
- `kubectl create configmap literal-config --from-literal=name=dave --from-literal=password=pass`

### **é€šä¿—è§£é‡Šï¼š`kubectl create configmap game-config --from-file=fire.file`**

è¿™æ¡å‘½ä»¤çš„ä½œç”¨æ˜¯ï¼š**æŠŠæœ¬åœ°çš„ä¸€ä¸ªæ–‡ä»¶ï¼ˆ`fire.file`ï¼‰å˜æˆ Kubernetes é‡Œçš„ä¸€ä¸ªâ€œé…ç½®åŒ…â€ï¼ˆ`ConfigMap`ï¼‰ï¼Œåå­—å« `game-config`ï¼Œæ–¹ä¾¿ Podï¼ˆå®¹å™¨ï¼‰è¯»å–é‡Œé¢çš„å†…å®¹ã€‚**

---

### **1. ä»€ä¹ˆæ˜¯ `ConfigMap`ï¼Ÿ**
- **`ConfigMap` æ˜¯ Kubernetes ç”¨æ¥å­˜é…ç½®çš„ä¸œè¥¿**ï¼Œæ¯”å¦‚é…ç½®æ–‡ä»¶ã€ç¯å¢ƒå˜é‡ç­‰ã€‚
- å®ƒä¸ä¼šå­˜æ•æ„Ÿä¿¡æ¯ï¼ˆå¯†ç ç”¨ `Secret`ï¼‰ï¼Œé€‚åˆå­˜æ™®é€šé…ç½®ï¼Œæ¯”å¦‚æ¸¸æˆå‚æ•°ã€æœåŠ¡å™¨åœ°å€ç­‰ã€‚
- Pod å¯ä»¥åƒè¯»æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ä¸€æ ·è¯»å– `ConfigMap` çš„å†…å®¹ã€‚

---

### **2. `--from-file=fire.file` æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**
- **`fire.file`**ï¼šæ˜¯ä½ ç”µè„‘ä¸Šçš„ä¸€ä¸ªæ–‡ä»¶ï¼ˆæ¯”å¦‚å†…å®¹å¯èƒ½æ˜¯ `max_players=10`ï¼‰ã€‚
- **`--from-file`**ï¼šå‘Šè¯‰ Kubernetes â€œæŠŠè¿™ä¸ªæ–‡ä»¶çš„å†…å®¹å¡è¿› `ConfigMap` é‡Œâ€ã€‚
- æ–‡ä»¶å†…å®¹ä¼šè¢«å­˜åˆ° `ConfigMap` çš„ `data` å­—æ®µä¸‹ï¼Œé”®åé»˜è®¤æ˜¯æ–‡ä»¶åï¼ˆ`fire.file`ï¼‰ã€‚

---

### **3. æ‰§è¡Œå‘½ä»¤åä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ**
- Kubernetes ä¼šåˆ›å»ºä¸€ä¸ªå« `game-config` çš„ `ConfigMap`ã€‚
- `fire.file` çš„å†…å®¹ä¼šè¢«å­˜è¿›å»ï¼Œæ¯”å¦‚ï¼š
  ```yaml
  apiVersion: v1
  kind: ConfigMap
  metadata:
    name: game-config
  data:
    fire.file: |  # é”®åæ˜¯æ–‡ä»¶åï¼Œå€¼æ˜¯æ–‡ä»¶å†…å®¹
      max_players=10
      level=hard
  ```

---

### **4. Pod æ€ä¹ˆç”¨è¿™ä¸ª `ConfigMap`ï¼Ÿ**
#### **æ–¹å¼1ï¼šæŒ‚è½½æˆæ–‡ä»¶ï¼ˆæœ€å¸¸ç”¨ï¼‰**
è®© Pod æŠŠ `ConfigMap` çš„å†…å®¹å˜æˆä¸€ä¸ªæ–‡ä»¶ï¼ˆæ¯”å¦‚ `/etc/game/config`ï¼‰ï¼š
```yaml
volumes:
  - name: config-volume
    configMap:
      name: game-config  # ä½¿ç”¨åˆšåˆ›å»ºçš„ConfigMap
containers:
  volumeMounts:
    - name: config-volume
      mountPath: /etc/game  # Podå†…ä¼šçœ‹åˆ°æ–‡ä»¶ï¼š/etc/game/fire.file
```

#### **æ–¹å¼2ï¼šæ³¨å…¥ç¯å¢ƒå˜é‡**
æŠŠ `ConfigMap` çš„å€¼å˜æˆç¯å¢ƒå˜é‡ï¼š
```yaml
env:
  - name: MAX_PLAYERS  # ç¯å¢ƒå˜é‡å
    valueFrom:
      configMapKeyRef:
        name: game-config
        key: fire.file  # ç›´æ¥å¼•ç”¨æ•´ä¸ªæ–‡ä»¶å†…å®¹
```

---

### **5. å®é™…ä¾‹å­**
å‡è®¾ `fire.file` å†…å®¹ï¼š
```ini
max_players=10
level=hard
```

**åˆ›å»º ConfigMapï¼š**
```bash
kubectl create configmap game-config --from-file=fire.file
```

**æŸ¥çœ‹å†…å®¹ï¼š**
```bash
kubectl get configmap game-config -o yaml
```
è¾“å‡ºï¼š
```yaml
data:
  fire.file: |
    max_players=10
    level=hard
```

---

### **6. å…¶ä»–ç”¨æ³•**
- **å¤šä¸ªæ–‡ä»¶**ï¼šå¯ä»¥ä¸€æ¬¡å¡å¤šä¸ªæ–‡ä»¶è¿›å»ï¼š
  ```bash
  kubectl create configmap my-config --from-file=file1 --from-file=file2
  ```
- **ç›®å½•**ï¼šç›´æ¥å¡æ•´ä¸ªç›®å½•çš„æ–‡ä»¶ï¼š
  ```bash
  kubectl create configmap dir-config --from-file=./configs/
  ```

---

### **æ€»ç»“**
- **è¿™æ¡å‘½ä»¤çš„ä½œç”¨**ï¼šæŠŠæœ¬åœ°æ–‡ä»¶ `fire.file` å˜æˆ Kubernetes çš„ `ConfigMap`ï¼ˆ`game-config`ï¼‰ã€‚
- **Pod æ€ä¹ˆç”¨**ï¼šæŒ‚è½½æˆæ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡ã€‚
- **é€‚ç”¨åœºæ™¯**ï¼šå­˜æ¸¸æˆçš„é…ç½®ã€æœåŠ¡å™¨å‚æ•°ç­‰éæ•æ„Ÿä¿¡æ¯ã€‚

ç›¸å½“äºæŠŠæ–‡ä»¶â€œä¸Šä¼ â€åˆ° Kubernetesï¼Œè®©æ‰€æœ‰ Pod éƒ½èƒ½æ–¹ä¾¿åœ°è¯»å–ï¼ ğŸš€


---


### **é€šä¿—è§£é‡Šï¼š`kubectl create configmap literal-config --from-literal=name=dave --from-literal=password=pass`**

è¿™æ¡å‘½ä»¤çš„ä½œç”¨æ˜¯ï¼š**ç›´æ¥åœ¨ Kubernetes é‡Œåˆ›å»ºä¸€ä¸ªå« `literal-config` çš„â€œé…ç½®åŒ…â€ï¼ˆ`ConfigMap`ï¼‰ï¼Œå¹¶å¾€é‡Œé¢å­˜ä¸¤å¯¹é”®å€¼ï¼ˆ`name=dave` å’Œ `password=pass`ï¼‰ï¼Œæ–¹ä¾¿ Podï¼ˆå®¹å™¨ï¼‰è¯»å–è¿™äº›å€¼ã€‚**

---

### **1. ä»€ä¹ˆæ˜¯ `ConfigMap`ï¼Ÿ**
- **`ConfigMap` æ˜¯ Kubernetes ç”¨æ¥å­˜é…ç½®çš„ä¸œè¥¿**ï¼Œæ¯”å¦‚ç¯å¢ƒå˜é‡ã€é…ç½®æ–‡ä»¶å†…å®¹ç­‰ã€‚
- å®ƒ**ä¸é€‚åˆå­˜æ•æ„Ÿä¿¡æ¯**ï¼ˆæ¯”å¦‚å¯†ç ï¼‰ï¼Œæ•æ„Ÿä¿¡æ¯åº”è¯¥ç”¨ `Secret`ã€‚
- è¿™é‡Œåªæ˜¯ä¸¾ä¾‹ï¼Œå®é™…å¯†ç ä¸è¦ç”¨ `ConfigMap` å­˜ï¼

---

### **2. `--from-literal` æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ**
- **`--from-literal`**ï¼šç›´æ¥å‘Šè¯‰ Kubernetes â€œæˆ‘è¦å­˜ä¸€ä¸ªé”®å€¼å¯¹â€ã€‚
- **`name=dave`**ï¼šé”®æ˜¯ `name`ï¼Œå€¼æ˜¯ `dave`ã€‚
- **`password=pass`**ï¼šé”®æ˜¯ `password`ï¼Œå€¼æ˜¯ `pass`ï¼ˆâš ï¸ å®é™…åˆ«è¿™ä¹ˆå¹²ï¼Œç”¨ `Secret`ï¼‰ã€‚

---

### **3. æ‰§è¡Œå‘½ä»¤åä¼šå‘ç”Ÿä»€ä¹ˆï¼Ÿ**
Kubernetes ä¼šåˆ›å»ºä¸€ä¸ª `ConfigMap`ï¼Œå†…å®¹å¦‚ä¸‹ï¼š
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: literal-config  # ä½ æŒ‡å®šçš„åå­—
data:
  name: dave      # é”®å€¼å¯¹1
  password: pass  # é”®å€¼å¯¹2ï¼ˆâš ï¸ å®é™…åˆ«è¿™ä¹ˆå­˜å¯†ç ï¼ï¼‰
```

---

### **4. Pod æ€ä¹ˆç”¨è¿™ä¸ª `ConfigMap`ï¼Ÿ**
#### **æ–¹å¼1ï¼šä½œä¸ºç¯å¢ƒå˜é‡ï¼ˆå¸¸ç”¨ï¼‰**
è®© Pod è¯»å– `ConfigMap` çš„å€¼å˜æˆç¯å¢ƒå˜é‡ï¼š
```yaml
env:
  - name: PLAYER_NAME  # Podå†…çš„ç¯å¢ƒå˜é‡å
    valueFrom:
      configMapKeyRef:
        name: literal-config  # ConfigMapåå­—
        key: name             # è¯»å–çš„é”®ï¼ˆdaveï¼‰
  - name: PLAYER_PASSWORD    # å¦ä¸€ä¸ªç¯å¢ƒå˜é‡
    valueFrom:
      configMapKeyRef:
        name: literal-config
        key: password         # è¯»å–çš„é”®ï¼ˆpassï¼‰
```

#### **æ–¹å¼2ï¼šæŒ‚è½½æˆæ–‡ä»¶**
æŠŠ `ConfigMap` çš„é”®å€¼å¯¹å˜æˆæ–‡ä»¶ï¼š
```yaml
volumes:
  - name: config-volume
    configMap:
      name: literal-config
containers:
  volumeMounts:
    - name: config-volume
      mountPath: /etc/config
```
Pod å†…ä¼šçœ‹åˆ°ï¼š
```
/etc/config/name      # å†…å®¹ï¼šdave
/etc/config/password  # å†…å®¹ï¼špass
```

---

### **5. å®é™…ä¾‹å­**
**åˆ›å»º ConfigMapï¼š**
```bash
kubectl create configmap literal-config --from-literal=name=dave --from-literal=password=pass
```

**æŸ¥çœ‹å†…å®¹ï¼š**
```bash
kubectl get configmap literal-config -o yaml
```
è¾“å‡ºï¼š
```yaml
data:
  name: dave
  password: pass
```

---

### **6. æ³¨æ„äº‹é¡¹**
1. **ä¸è¦ç”¨ `ConfigMap` å­˜å¯†ç ï¼**
  - è¿™ä¸ªä¾‹å­æ˜¯ä¸ºäº†æ¼”ç¤ºï¼Œå®é™…å¯†ç è¦ç”¨ `Secret`ï¼š
    ```bash
    kubectl create secret generic my-secret --from-literal=password=pass
    ```
2. **`--from-literal` vs `--from-file`**
  - `--from-literal`ï¼šç›´æ¥å†™é”®å€¼å¯¹ï¼ˆé€‚åˆå°‘é‡é…ç½®ï¼‰ã€‚
  - `--from-file`ï¼šä»æ–‡ä»¶åŠ è½½ï¼ˆé€‚åˆå¤§é…ç½®ï¼‰ã€‚

---

### **æ€»ç»“**
- **è¿™æ¡å‘½ä»¤çš„ä½œç”¨**ï¼šç›´æ¥åˆ›å»ºä¸€ä¸ª `ConfigMap`ï¼Œå¹¶å¾€é‡Œå­˜ `name=dave` å’Œ `password=pass`ã€‚
- **Pod æ€ä¹ˆç”¨**ï¼šå¯ä»¥å˜æˆç¯å¢ƒå˜é‡æˆ–æ–‡ä»¶ã€‚
- **é€‚ç”¨åœºæ™¯**ï¼šå­˜æ™®é€šé…ç½®ï¼ˆå¦‚ç”¨æˆ·åã€æœåŠ¡å™¨åœ°å€ï¼‰ï¼Œ**å¯†ç ç”¨ `Secret`**ï¼

ç›¸å½“äºå¾€ Kubernetes é‡Œâ€œæ‰‹å†™â€äº†ä¸€ä¸ªé…ç½®è¡¨ï¼Œè®© Pod éšä¾¿å–ç”¨ï¼ ğŸ› ï¸


#### fire.file

```yaml
name=tangfire
password=123
```


```bash
[root@k8s-master01 ~]# vim fire.file
[root@k8s-master01 ~]# 
[root@k8s-master01 ~]# 
[root@k8s-master01 ~]# kubectl create configmap game-config --from-file=fire.file
configmap/game-config created
[root@k8s-master01 ~]# 
[root@k8s-master01 ~]# kubectl get cm
NAME               DATA   AGE
game-config        1      6s
kube-root-ca.crt   1      7d1h

```

```bash
[root@k8s-master01 ~]# kubectl get cm game-config -o yaml
apiVersion: v1
data:
  fire.file: |
    name=tangfire
    password=123
kind: ConfigMap
metadata:
  creationTimestamp: "2025-07-10T14:09:14Z"
  name: game-config
  namespace: default
  resourceVersion: "925246"
  uid: 4f99811f-996b-4294-89f6-b2149065b981

```


```bash
[root@k8s-master01 ~]# kubectl describe cm game-config
Name:         game-config
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
fire.file:
----
name=tangfire
password=123


BinaryData
====

Events:  <none>
```


```bash
[root@k8s-master01 ~]# kubectl create configmap literal-config --from-literal=name=dave --from-literal=password=pass
configmap/literal-config created
```

```bash
[root@k8s-master01 ~]# kubectl get cm
NAME               DATA   AGE
game-config        1      7m1s
kube-root-ca.crt   1      7d1h
literal-config     2      91s
[root@k8s-master01 ~]# kubectl get cm literal-config -o yaml
apiVersion: v1
data:
  name: dave
  password: pass
kind: ConfigMap
metadata:
  creationTimestamp: "2025-07-10T14:14:44Z"
  name: literal-config
  namespace: default
  resourceVersion: "925746"
  uid: 2defc3aa-84e3-4de5-9163-a076d2000436
```


### configMap - ç¯å¢ƒå˜é‡

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: literal-config
  namespace: default
data:
  name: dave
  password: pass

```

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: env-config
  namespace: default
data:
  log_level: INFO
```


```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cm-env-test-pod
spec:
  imagePullSecrets:
    - name: aliyun-regcred
  containers:
    - name: test-container
      image: crpi-cd1z0kbw072xy0ao.cn-guangzhou.personal.cr.aliyuncs.com/tangfire/myversion:v1
      command: ["/bin/sh", "-c", "env"]  # å¯åŠ¨åæ‰§è¡Œenvå‘½ä»¤æ˜¾ç¤ºæ‰€æœ‰ç¯å¢ƒå˜é‡
      env:
        - name: USERNAME  # å•ä¸ªç¯å¢ƒå˜é‡å®šä¹‰
          valueFrom:
            configMapKeyRef:
              name: literal-config  # ä»åä¸ºliteral-configçš„ConfigMapè·å–
              key: name             # è·å–nameé”®å¯¹åº”çš„å€¼(dave)
        - name: PASSWORD  # å¦ä¸€ä¸ªç¯å¢ƒå˜é‡
          valueFrom:
            configMapKeyRef:
              name: literal-config
              key: password         # è·å–passwordé”®å¯¹åº”çš„å€¼(pass)
      envFrom:
        - configMapRef:
            name: env-config  # æ‰¹é‡å¯¼å…¥env-config ConfigMapçš„æ‰€æœ‰é”®å€¼
  restartPolicy: Never  # å®¹å™¨é€€å‡ºåä¸é‡å¯
```

#### ConfigMap - ENV(2.pod.yaml)



```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: literal-config
  namespace: default
data:
  name: dave
  password: pass

---

apiVersion: v1
kind: ConfigMap
metadata:
  name: env-config
  namespace: default
data:
  log_level: INFO


---

apiVersion: v1
kind: Pod
metadata:
  name: cm-env-test-pod
spec:
  imagePullSecrets:
    - name: aliyun-secret
  containers:
    - name: test-container
      image: crpi-cd1z0kbw072xy0ao.cn-guangzhou.personal.cr.aliyuncs.com/tangfire/myversion:v1
      command: ["/bin/sh", "-c", "env"]  # å¯åŠ¨åæ‰§è¡Œenvå‘½ä»¤æ˜¾ç¤ºæ‰€æœ‰ç¯å¢ƒå˜é‡
      env:
        - name: USERNAME  # å•ä¸ªç¯å¢ƒå˜é‡å®šä¹‰
          valueFrom:
            configMapKeyRef:
              name: literal-config  # ä»åä¸ºliteral-configçš„ConfigMapè·å–
              key: name             # è·å–nameé”®å¯¹åº”çš„å€¼(dave)
        - name: PASSWORD  # å¦ä¸€ä¸ªç¯å¢ƒå˜é‡
          valueFrom:
            configMapKeyRef:
              name: literal-config
              key: password         # è·å–passwordé”®å¯¹åº”çš„å€¼(pass)
      envFrom:
        - configMapRef:
            name: env-config  # æ‰¹é‡å¯¼å…¥env-config ConfigMapçš„æ‰€æœ‰é”®å€¼
  restartPolicy: Never  # å®¹å™¨é€€å‡ºåä¸é‡å¯

```


```bash
[root@k8s-master01 7]# kubectl apply -f 2.pod.yaml 
configmap/literal-config created
configmap/env-config created
pod/cm-env-test-pod created
[root@k8s-master01 7]# kubectl get pod
NAME                    READY   STATUS      RESTARTS   AGE
cm-env-test-pod         0/1     Completed   0          5s
readiness-httpget-pod   0/1     Running     0          19h
[root@k8s-master01 7]# kubectl logs cm-env-test-pod
KUBERNETES_SERVICE_PORT=443
KUBERNETES_PORT=tcp://10.0.0.1:443
HOSTNAME=cm-env-test-pod
SHLVL=1
HOME=/root
MYAPP_SERVICE_HOST=10.13.161.153
PKG_RELEASE=1
MYAPP_PORT=tcp://10.13.161.153:80
MYAPP_SERVICE_PORT=80
USERNAME=dave
KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1
NGINX_VERSION=1.25.5
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
MYAPP_PORT_80_TCP_ADDR=10.13.161.153
KUBERNETES_PORT_443_TCP_PORT=443
NJS_VERSION=0.8.4
KUBERNETES_PORT_443_TCP_PROTO=tcp
MYAPP_SERVICE_PORT_80_80=80
MYAPP_PORT_80_TCP_PORT=80
NJS_RELEASE=3
MYAPP_PORT_80_TCP_PROTO=tcp
log_level=INFO
KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_SERVICE_HOST=10.0.0.1
MYAPP_PORT_80_TCP=tcp://10.13.161.153:80
PWD=/
PASSWORD=pass
```


### configMap - å¯åŠ¨å‘½ä»¤


```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: literal-config
  namespace: default
data:
  name: dave
  password: pass

```

#### 3.pod.yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cm-command-pod
spec:
  imagePullSecrets:
    - name: aliyun-secret
  containers:
    - name: myapp-container
      image: crpi-cd1z0kbw072xy0ao.cn-guangzhou.personal.cr.aliyuncs.com/tangfire/myversion:v1
      command: ["/bin/sh", "-c", "echo $(USERNAME) $(PASSWORD)"]
      env:
        - name: USERNAME
          valueFrom:
            configMapKeyRef:
              name: literal-config
              key: name
        - name: PASSWORD
          valueFrom:
            configMapKeyRef:
              name: literal-config
              key: password
  restartPolicy: Never
```

```bash
[root@k8s-master01 7]# kubectl apply -f 3.pod.yaml 
pod/cm-command-pod created
[root@k8s-master01 7]# kubectl get pod
NAME                    READY   STATUS      RESTARTS   AGE
cm-command-pod          0/1     Completed   0          5s
cm-env-test-pod         0/1     Completed   0          5m1s
readiness-httpget-pod   0/1     Running     0          19h
[root@k8s-master01 7]# kubectl logs cm-command-pod
dave pass
```


### configMap - æ–‡ä»¶



```yaml
apiVersion: v1
kind: Pod
metadata:
  name: cm-volume-pod
spec:
  imagePullSecrets:
    - name: aliyun-secret
  containers:
    - name: myapp-container
      image: crpi-cd1z0kbw072xy0ao.cn-guangzhou.personal.cr.aliyuncs.com/tangfire/myversion:v1
      volumeMounts:
        - name: config-volume
          mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: literal-config
  restartPolicy: Never
```

```bash
[root@k8s-master01 7]# kubectl apply -f 4.pod.yaml 
pod/cm-volume-pod created
[root@k8s-master01 7]# kubectl exec -it cm-volume-pod -- /bin/sh
/ # cd /etc/config
/etc/config # ls
name      password
/etc/config # cat name
dave/etc/config # cat password
pass/etc/config # ^C

/etc/config # exit
command terminated with exit code 130
[root@k8s-master01 7]# ^C
```


### configMap - çƒ­æ›´æ–° - 1

#### default.conf

```nginx
server {
    listen 80 default_server;
    server_name example.com www.example.com;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
}
```

```bash
[root@k8s-master01 5]# kubectl create cm default-nginx --from-file=default.conf
configmap/default-nginx created
[root@k8s-master01 5]# kubectl get cm
NAME               DATA   AGE
default-nginx      1      18s

[root@k8s-master01 5]# kubectl create cm default-nginx --from-file=default.conf
configmap/default-nginx created
[root@k8s-master01 5]# kubectl get cm
NAME               DATA   AGE
default-nginx      1      18s
env-config         1      3h30m
game-config        1      15h
kube-root-ca.crt   1      7d16h
literal-config     2      3h30m
[root@k8s-master01 5]# ^C
[root@k8s-master01 5]# kubectl get cm default-nginx -o yaml
apiVersion: v1
data:
  default.conf: "server {\n    listen 80 default_server;\n    server_name example.com
    www.example.com;\n    \n    location / {\n        root /usr/share/nginx/html;\n
    \       index index.html index.htm;\n    }\n}\n"
kind: ConfigMap
metadata:
  creationTimestamp: "2025-07-11T05:34:46Z"
  name: default-nginx
  namespace: default
  resourceVersion: "1008811"
  uid: 7c1dfcda-8a7e-4fff-829f-c2b13f2f6c25
  
  
```




#### deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: hotupdate-deploy
  name: hotupdate-deploy
spec:
  replicas: 5
  selector:
    matchLabels:
      app: hotupdate-deploy
  template:
    metadata:
      labels:
        app: hotupdate-deploy
    spec:
      containers:
      - image: nginx:1.25
        name: nginx
        volumeMounts:
        - name: config-volume
          mountPath: /etc/nginx/conf.d/
      volumes:
      - name: config-volume
        configMap:
          name: default-nginx
```


```bash
[root@k8s-master01 5]# kubectl apply -f deployment.yaml 
deployment.apps/hotupdate-deploy created
[root@k8s-master01 5]# kubectl get pod
NAME                                READY   STATUS    RESTARTS   AGE
hotupdate-deploy-685f59b5d7-8pb9r   1/1     Running   0          6s
hotupdate-deploy-685f59b5d7-j62fw   1/1     Running   0          6s
hotupdate-deploy-685f59b5d7-mcphd   1/1     Running   0          6s
hotupdate-deploy-685f59b5d7-ql5wg   1/1     Running   0          6s
hotupdate-deploy-685f59b5d7-xvg9p   1/1     Running   0          6s
[root@k8s-master01 5]# ^C
[root@k8s-master01 5]# 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl exec -it hotupdate-deploy-685f59b5d7-8pb9r -- /bin/bash
root@hotupdate-deploy-685f59b5d7-8pb9r:/# 
root@hotupdate-deploy-685f59b5d7-8pb9r:/# 
root@hotupdate-deploy-685f59b5d7-8pb9r:/# cd /etc/nginx/conf.d
root@hotupdate-deploy-685f59b5d7-8pb9r:/etc/nginx/conf.d# ls
default.conf
root@hotupdate-deploy-685f59b5d7-8pb9r:/etc/nginx/conf.d# cat default.conf 
server {
    listen 80 default_server;
    server_name example.com www.example.com;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
}
```
å†èµ·ä¸€ä¸ªç»ˆç«¯ï¼Œæ‰§è¡Œï¼š

```bash
[root@k8s-master01 6]# kubectl edit cm default-nginx
configmap/default-nginx edited
```

å°†ç«¯å£ä»80æ”¹æˆ8080

```bash
[root@k8s-master01 6]# kubectl get cm default-nginx -o yaml
apiVersion: v1
data:
  default.conf: "server {\n    listen 8080 default_server;\n    server_name example.com
    www.example.com;\n    \n    location / {\n        root /usr/share/nginx/html;\n
    \       index index.html index.htm;\n    }\n}\n"
kind: ConfigMap
metadata:
  creationTimestamp: "2025-07-11T05:34:46Z"
  name: default-nginx
  namespace: default
  resourceVersion: "1011934"
  uid: 7c1dfcda-8a7e-4fff-829f-c2b13f2f6c25
```

```bash
root@hotupdate-deploy-685f59b5d7-8pb9r:/etc/nginx/conf.d# cat default.conf 
server {
    listen 8080 default_server;
    server_name example.com www.example.com;
    
    location / {
        root /usr/share/nginx/html;
        index index.html index.htm;
    }
}
```

```bash
[root@k8s-master01 5]# kubectl get pod -o wide
NAME                                READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
hotupdate-deploy-685f59b5d7-8pb9r   1/1     Running   0          38m   10.244.58.202   k8s-node02   <none>           <none>
hotupdate-deploy-685f59b5d7-j62fw   1/1     Running   0          38m   10.244.85.245   k8s-node01   <none>           <none>
hotupdate-deploy-685f59b5d7-mcphd   1/1     Running   0          38m   10.244.58.204   k8s-node02   <none>           <none>
hotupdate-deploy-685f59b5d7-ql5wg   1/1     Running   0          38m   10.244.58.201   k8s-node02   <none>           <none>
hotupdate-deploy-685f59b5d7-xvg9p   1/1     Running   0          38m   10.244.85.244   k8s-node01   <none>           <none>
[root@k8s-master01 5]# curl 10.244.58.202
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>
[root@k8s-master01 5]# curl 10.244.58.202:8080
curl: (7) Failed to connect to 10.244.58.202 port 8080: Connection refused
```


### configMap - çƒ­æ›´æ–° - 2


![128](../img/img_128.png)


```bash
kubectl patch deployment hotupdate-deploy --patch '{"spec":{"template":{"metadata":{"annotations":{"version/config":"666666666"}}}}}'
```


```bash
[root@k8s-master01 5]# kubectl patch deployment hotupdate-deploy --patch '{"spec":{"template":{"metadata":{"annotations":{"version/config":"666666666"}}}}}'
deployment.apps/hotupdate-deploy patched

[root@k8s-master01 5]# kubectl get pod -o wide
NAME                                READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATES
hotupdate-deploy-7b4b64978c-2djbf   1/1     Running   0          115s   10.244.85.247   k8s-node01   <none>           <none>
hotupdate-deploy-7b4b64978c-7d79b   1/1     Running   0          116s   10.244.85.246   k8s-node01   <none>           <none>
hotupdate-deploy-7b4b64978c-m4jhm   1/1     Running   0          114s   10.244.58.209   k8s-node02   <none>           <none>
hotupdate-deploy-7b4b64978c-t8g8m   1/1     Running   0          116s   10.244.58.203   k8s-node02   <none>           <none>
hotupdate-deploy-7b4b64978c-w52dw   1/1     Running   0          116s   10.244.58.206   k8s-node02   <none>           <none>
[root@k8s-master01 5]# curl 10.244.85.247:8080
<!DOCTYPE html>
<html>
<head>
<title>Welcome to nginx!</title>
<style>
html { color-scheme: light dark; }
body { width: 35em; margin: 0 auto;
font-family: Tahoma, Verdana, Arial, sans-serif; }
</style>
</head>
<body>
<h1>Welcome to nginx!</h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>

<p>For online documentation and support please refer to
<a href="http://nginx.org/">nginx.org</a>.<br/>
Commercial support is available at
<a href="http://nginx.com/">nginx.com</a>.</p>

<p><em>Thank you for using nginx.</em></p>
</body>
</html>

[root@k8s-master01 5]# curl 10.244.85.247:80
curl: (7) Failed to connect to 10.244.85.247 port 80: Connection refused
```


### configMap - ä¸å¯æ”¹å˜



![129](../img/img_129.png)

```bash
kubectl edit cm default-nginx
```

æ·»åŠ `immutable: true`

```yaml
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#
apiVersion: v1
data:
  default.conf: "server {\n    listen 8080 default_server;\n    server_name example.com
    www.example.com;\n    \n    location / {\n        root /usr/share/nginx/html;\n
    \       index index.html index.htm;\n    }\n}\n"
kind: ConfigMap
immutable: true
metadata:
  creationTimestamp: "2025-07-11T05:34:46Z"
  name: default-nginx
  namespace: default
  resourceVersion: "1011934"
  uid: 7c1dfcda-8a7e-4fff-829f-c2b13f2f6c25
```



- cm å¦‚æœä¿®æ”¹ä¸ºä¸å¯æ”¹å˜çš„çŠ¶æ€ï¼Œæ˜¯ä¸å…è®¸å›é€€çš„ï¼Œæ˜¯ä¸å¯é€†çš„ã€‚
- å¯ä»¥åˆ é™¤æ­¤cmï¼Œç„¶åé‡æ–°åˆ›å»ºä¸€ä¸ªæ— ä¸å¯æ”¹å˜æ ‡è®°çš„cm
- ä¼˜ç‚¹ï¼š
  - é˜²æ­¢å‡ºç°ä¸€äº›é”™è¯¯çš„ä¿®æ”¹
  - å‡å°‘å¯¹apiServerè¯·æ±‚å‹åŠ›

  

 

## 03. Secret

ç¼–ç è€Œæ¥çš„å®‰å…¨

### Secret - å®šä¹‰

![130](../img/img_130.png)


### Secret - ç‰¹æ€§

![131](../img/img_131.png)


### Secret - ç±»å‹

![132](../img/img_132.png)


### Secret - Opaque - æ¦‚å¿µ


![133](../img/img_133.png)

### Secret - Opaque - åˆ›å»º



![134](../img/img_134.png)

```bash
[root@k8s-master01 5]# echo -n "tangfire" | base64
dGFuZ2ZpcmU=
[root@k8s-master01 5]# echo -n "dGFuZ2ZpcmU=" | base64 -d
tangfire[root@k8s-master01 5]# 
[root@k8s-master01 5]#  echo -n "123456" | base64
MTIzNDU2
```

#### 7.secret.yaml


```yaml
apiVersion: v1
kind: Secret
metadata:
  name: mysecret
type: Opaque
data:
  password: MTIzNDU2
  username: dGFuZ2ZpcmU=
```


```bash
[root@k8s-master01 5]# vim 7.secret.yaml 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl apply -f 7.secret.yaml 
secret/mysecret created
[root@k8s-master01 5]# kubectl get secret
NAME            TYPE                             DATA   AGE
aliyun-secret   kubernetes.io/dockerconfigjson   1      2d22h
mysecret        Opaque                           2      5s
[root@k8s-master01 5]# kubectl describe secret mysecret
Name:         mysecret
Namespace:    default
Labels:       <none>
Annotations:  <none>

Type:  Opaque

Data
====
password:  6 bytes
username:  8 bytes
```

```bash
[root@k8s-master01 5]# kubectl get secret mysecret -o yaml
apiVersion: v1
data:
  password: MTIzNDU2
  username: dGFuZ2ZpcmU=
kind: Secret
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","data":{"password":"MTIzNDU2","username":"dGFuZ2ZpcmU="},"kind":"Secret","metadata":{"annotations":{},"name":"mysecret","namespace":"default"},"type":"Opaque"}
  creationTimestamp: "2025-07-11T11:03:44Z"
  name: mysecret
  namespace: default
  resourceVersion: "1038681"
  uid: 79c4de3e-6b3a-48ce-9121-0b4110a8c910
type: Opaque
[root@k8s-master01 5]# echo -n "MTIzNDU2" | base64 -d
123456[root@k8s-master01 5]# 
```


### Secret - Opaque - ENV

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: opaque-secret-env
  name: opaque-secret-env-deploy
spec:
  replicas: 5
  selector:
    matchLabels:
      app: op-se-env-pod
  template:
    metadata:
      labels:
        app: op-se-env-pod
    spec:
      imagePullSecrets:
        - name: aliyun-secret
      containers:
      - name: myapp-container
        image: crpi-cd1z0kbw072xy0ao.cn-guangzhou.personal.cr.aliyuncs.com/tangfire/myversion:v1
        ports:
        - containerPort: 80
        env:
        - name: TEST_USER
          valueFrom:
            secretKeyRef:
              name: mysecret
              key: username
        - name: TEST_PASSWORD
          valueFrom:
            secretKeyRef:
              name: mysecret
              key: password
```



```bash
[root@k8s-master01 5]# vim 8.deployment.yaml
[root@k8s-master01 5]# 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl apply -f 8.deployment.yaml 
deployment.apps/opaque-secret-env-deploy created
```

```bash
[root@k8s-master01 5]# kubectl get pod
NAME                                        READY   STATUS    RESTARTS   AGE
opaque-secret-env-deploy-7b945c5f98-9mzzp   1/1     Running   0          43s
opaque-secret-env-deploy-7b945c5f98-f5252   1/1     Running   0          43s
opaque-secret-env-deploy-7b945c5f98-hxfcx   1/1     Running   0          43s
opaque-secret-env-deploy-7b945c5f98-qfwnj   1/1     Running   0          43s
opaque-secret-env-deploy-7b945c5f98-xrxw5   1/1     Running   0          43s
[root@k8s-master01 5]# kubectl exec -it opaque-secret-env-deploy-7b945c5f98-9mzzp -- /bin/sh 
/ # env
KUBERNETES_SERVICE_PORT=443
KUBERNETES_PORT=tcp://10.0.0.1:443
HOSTNAME=opaque-secret-env-deploy-7b945c5f98-9mzzp
SHLVL=1
HOME=/root
TEST_PASSWORD=123456
PKG_RELEASE=1
TEST_USER=tangfire
TERM=xterm
KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1
NGINX_VERSION=1.25.5
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
KUBERNETES_PORT_443_TCP_PORT=443
NJS_VERSION=0.8.4
KUBERNETES_PORT_443_TCP_PROTO=tcp
NJS_RELEASE=3
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443
KUBERNETES_SERVICE_HOST=10.0.0.1
PWD=/
/ # 
```


### Secret - Opaque - Volume


![135](../img/img_135.png)

#### 9.pod.yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    name: secret-volume
  name: secret-volume-pod
spec:
  imagePullSecrets:
    - name: aliyun-secret
  volumes:
    - name: volumes12
      secret:
        secretName: mysecret
  containers:
    - image: crpi-cd1z0kbw072xy0ao.cn-guangzhou.personal.cr.aliyuncs.com/tangfire/myversion:v1
      name: myapp-container
      volumeMounts:
        - name: volumes12
          mountPath: /data
```

```bash
[root@k8s-master01 5]# vim 9.pod.yaml
[root@k8s-master01 5]# 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl apply -f 9.pod.yaml 
pod/secret-volume-pod created
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl get pod
NAME                READY   STATUS    RESTARTS   AGE
secret-volume-pod   1/1     Running   0          27s
[root@k8s-master01 5]# kubectl exec -it secret-volume-pod -- /bin/sh
/ # 
/ # cd /data/
/data # ls
password  username
/data # cat username
tangfire/data # cat password
123456/data # 
```



### Secret - Opaque - Volume - çƒ­æ›´æ–°


![136](../img/img_136.png)



### Secret - Opaque - Volume - ä¸å¯æ›´æ”¹

![137](../img/img_137.png)




## 04. Downward API


å®¹å™¨åœ¨è¿è¡Œæ—¶ä»Kubernetes APIæœåŠ¡å™¨è·å–æœ‰å…³å®ƒä»¬è‡ªèº«çš„ä¿¡æ¯


### Downward API - å­˜åœ¨çš„æ„ä¹‰


![138](../img/img_138.png)


### Downward API - envæ¡ˆä¾‹

#### 12.pod.yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: downward-api-env-example
spec:
  containers:
    - name: my-container
      image: wangyanglinux/myapp:v1.0
      env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        - name: CPU_REQUEST
          valueFrom:
            resourceFieldRef:
              containerName: my-container
              resource: requests.cpu
        - name: CPU_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: my-container
              resource: limits.cpu
        - name: MEMORY_REQUEST
          valueFrom:
            resourceFieldRef:
              containerName: my-container
              resource: requests.memory
        - name: MEMORY_LIMIT
          valueFrom:
            resourceFieldRef:
              containerName: my-container
              resource: limits.memory
  restartPolicy: Never
```

```bash
[root@k8s-master01 5]# vim 12.pod.yaml
[root@k8s-master01 5]# 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl apply -f 12.pod.yaml 
pod/downward-api-env-example created
[root@k8s-master01 5]# 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl get pod
NAME                       READY   STATUS              RESTARTS   AGE
downward-api-env-example   0/1     ContainerCreating   0          6s
secret-volume-pod          1/1     Running             0          96m
[root@k8s-master01 5]# kubectl get pod
NAME                       READY   STATUS    RESTARTS   AGE
downward-api-env-example   1/1     Running   0          48s
secret-volume-pod          1/1     Running   0          96m
[root@k8s-master01 5]# kubectl exec -it downward-api-env-example -- /bin/bash
downward-api-env-example:/# 
downward-api-env-example:/# env
KUBERNETES_SERVICE_PORT_HTTPS=443
KUBERNETES_SERVICE_PORT=443
CHARSET=UTF-8
HOSTNAME=downward-api-env-example
CPU_REQUEST=0
POD_NAME=downward-api-env-example
POD_NAMESPACE=default
PWD=/
HOME=/root
LANG=C.UTF-8
KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443
TERM=xterm
SHLVL=1
KUBERNETES_PORT_443_TCP_PROTO=tcp
KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1
POD_IP=10.244.58.213
CPU_LIMIT=4
MEMORY_LIMIT=3698946048
KUBERNETES_SERVICE_HOST=10.0.0.1
KUBERNETES_PORT=tcp://10.0.0.1:443
MEMORY_REQUEST=0
KUBERNETES_PORT_443_TCP_PORT=443
LC_COLLATE=C
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
_=/usr/bin/env
downward-api-env-example:/# 
```

### Downward API - volumeæ¡ˆä¾‹

#### 13.pod.yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: downward-api-volume-example
spec:
  containers:
    - name: my-container
      image: wangyanglinux/myapp:v1.0
      resources:
        limits:
          cpu: "1"
          memory: "512Mi"
        requests:
          cpu: "0.5"
          memory: "256Mi"
      volumeMounts:
        - name: downward-api-volume
          mountPath: /etc/podinfo
  volumes:
    - name: downward-api-volume
      downwardAPI:
        items:
          - path: "annotations"
            fieldRef:
              fieldPath: metadata.annotations
          - path: "labels"
            fieldRef:
              fieldPath: metadata.labels
          - path: "name"
            fieldRef:
              fieldPath: metadata.name
          - path: "namespace"
            fieldRef:
              fieldPath: metadata.namespace
          - path: "uid"
            fieldRef:
              fieldPath: metadata.uid
          - path: "cpuRequest"
            resourceFieldRef:
              containerName: my-container
              resource: requests.cpu
          - path: "memoryRequest"
            resourceFieldRef:
              containerName: my-container
              resource: requests.memory
          - path: "cpuLimit"
            resourceFieldRef:
              containerName: my-container
              resource: limits.cpu
          - path: "memoryLimit"
            resourceFieldRef:
              containerName: my-container
              resource: limits.memory
  restartPolicy: Never
```

### **é€šä¿—è§£é‡Šï¼šKubernetes Downward API å·æŒ‚è½½é…ç½®**

è¿™ä¸ª YAML å®šä¹‰äº†ä¸€ä¸ª Podï¼Œåä¸º `downward-api-volume-example`ï¼Œå®ƒé€šè¿‡ **Downward API** å°† Pod è‡ªèº«çš„å…ƒæ•°æ®ï¼ˆå¦‚åç§°ã€å‘½åç©ºé—´ã€æ ‡ç­¾ç­‰ï¼‰å’Œèµ„æºé™åˆ¶ï¼ˆCPUã€å†…å­˜ï¼‰ä»¥æ–‡ä»¶çš„å½¢å¼æŒ‚è½½åˆ°å®¹å™¨å†…éƒ¨ï¼ˆ`/etc/podinfo`ï¼‰ã€‚

---

## **1. æ ¸å¿ƒåŠŸèƒ½**
- **Downward API**ï¼šKubernetes æä¾›çš„ä¸€ç§æœºåˆ¶ï¼Œå…è®¸ Pod **è·å–è‡ªèº«çš„è¿è¡Œæ—¶ä¿¡æ¯**ï¼ˆå¦‚ Pod åç§°ã€IPã€èµ„æºé™åˆ¶ç­‰ï¼‰ã€‚
- **ç”¨é€”**ï¼šåº”ç”¨ç¨‹åºå¯ä»¥é€šè¿‡è¯»å– `/etc/podinfo` ç›®å½•ä¸‹çš„æ–‡ä»¶ï¼ŒåŠ¨æ€è·å– Pod çš„å…ƒæ•°æ®å’Œèµ„æºé…é¢ï¼Œè€Œæ— éœ€ç¡¬ç¼–ç æˆ–ä¾èµ–å¤–éƒ¨æŸ¥è¯¢ã€‚

---

## **2. å…³é”®é…ç½®è§£æ**
### **(1) Pod åŸºæœ¬ä¿¡æ¯**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: downward-api-volume-example
```
- **`apiVersion: v1`**ï¼šä½¿ç”¨ Kubernetes æ ¸å¿ƒ APIã€‚
- **`kind: Pod`**ï¼šå®šä¹‰çš„æ˜¯ä¸€ä¸ª Pod èµ„æºã€‚
- **`metadata.name`**ï¼šPod åç§°æ˜¯ `downward-api-volume-example`ã€‚

---

### **(2) å®¹å™¨é…ç½®**
```yaml
spec:
  containers:
    - name: my-container
      image: wangyanglinux/myapp:v1.0
      resources:
        limits:
          cpu: "1"
          memory: "512Mi"
        requests:
          cpu: "0.5"
          memory: "256Mi"
```
- **`image: wangyanglinux/myapp:v1.0`**ï¼šå®¹å™¨ä½¿ç”¨çš„é•œåƒã€‚
- **`resources`**ï¼šå®šä¹‰å®¹å™¨çš„èµ„æºé™åˆ¶å’Œè¯·æ±‚ï¼š
  - **`limits`**ï¼ˆç¡¬é™åˆ¶ï¼‰ï¼š
    - CPUï¼šæœ€å¤š 1 æ ¸
    - å†…å­˜ï¼šæœ€å¤š 512MB
  - **`requests`**ï¼ˆæœ€ä½éœ€æ±‚ï¼‰ï¼š
    - CPUï¼šè‡³å°‘ 0.5 æ ¸
    - å†…å­˜ï¼šè‡³å°‘ 256MB

---

### **(3) Downward API å·æŒ‚è½½**
```yaml
volumeMounts:
  - name: downward-api-volume
    mountPath: /etc/podinfo  # æŒ‚è½½åˆ°å®¹å™¨å†…çš„è·¯å¾„
```
- **`volumeMounts`**ï¼šå°† `downward-api-volume` æŒ‚è½½åˆ°å®¹å™¨çš„ `/etc/podinfo` ç›®å½•ã€‚
- **å®¹å™¨å†…ä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶**ï¼š
  - `/etc/podinfo/annotations`ï¼ˆPod çš„æ³¨è§£ï¼‰
  - `/etc/podinfo/labels`ï¼ˆPod çš„æ ‡ç­¾ï¼‰
  - `/etc/podinfo/name`ï¼ˆPod åç§°ï¼‰
  - `/etc/podinfo/namespace`ï¼ˆPod æ‰€åœ¨çš„å‘½åç©ºé—´ï¼‰
  - `/etc/podinfo/uid`ï¼ˆPod çš„å”¯ä¸€ IDï¼‰
  - `/etc/podinfo/cpuRequest`ï¼ˆCPU è¯·æ±‚å€¼ï¼‰
  - `/etc/podinfo/memoryRequest`ï¼ˆå†…å­˜è¯·æ±‚å€¼ï¼‰
  - `/etc/podinfo/cpuLimit`ï¼ˆCPU é™åˆ¶å€¼ï¼‰
  - `/etc/podinfo/memoryLimit`ï¼ˆå†…å­˜é™åˆ¶å€¼ï¼‰

---

### **(4) Downward API å·å®šä¹‰**
```yaml
volumes:
  - name: downward-api-volume
    downwardAPI:
      items:
        - path: "annotations"  # æ–‡ä»¶å
          fieldRef:
            fieldPath: metadata.annotations  # æ•°æ®æ¥æº
        - path: "labels"
          fieldRef:
            fieldPath: metadata.labels
        - path: "name"
          fieldRef:
            fieldPath: metadata.name
        - path: "namespace"
          fieldRef:
            fieldPath: metadata.namespace
        - path: "uid"
          fieldRef:
            fieldPath: metadata.uid
        - path: "cpuRequest"
          resourceFieldRef:
            containerName: my-container  # æŒ‡å®šå®¹å™¨
            resource: requests.cpu      # è·å– CPU è¯·æ±‚å€¼
        - path: "memoryRequest"
          resourceFieldRef:
            containerName: my-container
            resource: requests.memory
        - path: "cpuLimit"
          resourceFieldRef:
            containerName: my-container
            resource: limits.cpu
        - path: "memoryLimit"
          resourceFieldRef:
            containerName: my-container
            resource: limits.memory
```
- **`downwardAPI`**ï¼šå®šä¹‰ Downward API å·ï¼Œå°† Pod ä¿¡æ¯å†™å…¥æ–‡ä»¶ã€‚
- **`items`**ï¼šæŒ‡å®šè¦æš´éœ²å“ªäº›ä¿¡æ¯ï¼Œæ¯ä¸ª `path` å¯¹åº”ä¸€ä¸ªæ–‡ä»¶åï¼Œ`fieldRef` æˆ– `resourceFieldRef` æŒ‡å®šæ•°æ®æ¥æºã€‚

---

### **(5) é‡å¯ç­–ç•¥**
```yaml
restartPolicy: Never
```
- **`Never`**ï¼šPod é€€å‡ºåä¸ä¼šè‡ªåŠ¨é‡å¯ï¼ˆé€‚åˆä¸€æ¬¡æ€§ä»»åŠ¡ï¼‰ã€‚

---

## **3. å®é™…åº”ç”¨åœºæ™¯**
1. **æ—¥å¿—æ”¶é›†**ï¼šåº”ç”¨ç¨‹åºå¯ä»¥è¯»å– `/etc/podinfo/name` è·å– Pod åç§°ï¼Œç”¨äºæ—¥å¿—æ ‡è®°ã€‚
2. **åŠ¨æ€é…ç½®**ï¼šæ ¹æ® Pod çš„å‘½åç©ºé—´ï¼ˆ`namespace`ï¼‰æˆ–æ ‡ç­¾ï¼ˆ`labels`ï¼‰è°ƒæ•´è¿è¡Œå‚æ•°ã€‚
3. **èµ„æºç›‘æ§**ï¼šé€šè¿‡ `cpuLimit`ã€`memoryLimit` ç­‰æ–‡ä»¶ï¼Œè®©åº”ç”¨çŸ¥é“è‡ªå·±çš„èµ„æºé…é¢ã€‚

---

## **4. ç¤ºä¾‹ï¼šå®¹å™¨å†…æŸ¥çœ‹æ–‡ä»¶**
```bash
kubectl exec downward-api-volume-example -- cat /etc/podinfo/name
# è¾“å‡ºï¼šdownward-api-volume-example

kubectl exec downward-api-volume-example -- cat /etc/podinfo/cpuLimit
# è¾“å‡ºï¼š1
```

---

## **æ€»ç»“**
- **Downward API** è®© Pod èƒ½è·å–è‡ªèº«ä¿¡æ¯ï¼Œæ— éœ€ä¾èµ–å¤–éƒ¨æŸ¥è¯¢ã€‚
- **æŒ‚è½½æˆæ–‡ä»¶** åï¼Œåº”ç”¨ç¨‹åºå¯ä»¥ç›´æ¥è¯»å–ï¼Œé€‚ç”¨äºåŠ¨æ€é…ç½®ã€æ—¥å¿—æ ‡è®°ç­‰åœºæ™¯ã€‚
- **èµ„æºé™åˆ¶**ï¼ˆCPU/å†…å­˜ï¼‰ä¹Ÿèƒ½é€šè¿‡æ–‡ä»¶æš´éœ²ï¼Œæ–¹ä¾¿åº”ç”¨è‡ªé€‚åº”è°ƒæ•´ã€‚

è¿™æ ·è®¾è®¡çš„å¥½å¤„æ˜¯ **è§£è€¦**ï¼Œåº”ç”¨ç¨‹åºä¸éœ€è¦ç¡¬ç¼–ç  Pod ä¿¡æ¯ï¼Œè€Œæ˜¯åŠ¨æ€è·å–ï¼Œæé«˜å¯ç§»æ¤æ€§ã€‚ ğŸš€

```bash
[root@k8s-master01 5]# vim 13.pod.yaml
[root@k8s-master01 5]# 
[root@k8s-master01 5]# 
[root@k8s-master01 5]# kubectl apply -f 13.pod.yaml 
pod/downward-api-volume-example created
[root@k8s-master01 5]# kubectl get pod
NAME                          READY   STATUS              RESTARTS   AGE
downward-api-env-example      1/1     Running             0          22m
downward-api-volume-example   0/1     ContainerCreating   0          3s
secret-volume-pod             1/1     Running             0          118m
[root@k8s-master01 5]# kubectl exec -it downward-api-volume-example /bin/bash
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
error: unable to upgrade connection: container not found ("my-container")
[root@k8s-master01 5]# kubectl exec -it downward-api-volume-example --  /bin/bash
downward-api-volume-example:/# cd /etc/podinfo/
downward-api-volume-example:/etc/podinfo# ls
annotations    cpuRequest     memoryLimit    name           uid
cpuLimit       labels         memoryRequest  namespace
downward-api-volume-example:/etc/podinfo# ls -l
total 0
lrwxrwxrwx    1 root     root            18 Jul 11 21:36 annotations -> ..data/annotations
lrwxrwxrwx    1 root     root            15 Jul 11 21:36 cpuLimit -> ..data/cpuLimit
lrwxrwxrwx    1 root     root            17 Jul 11 21:36 cpuRequest -> ..data/cpuRequest
lrwxrwxrwx    1 root     root            13 Jul 11 21:36 labels -> ..data/labels
lrwxrwxrwx    1 root     root            18 Jul 11 21:36 memoryLimit -> ..data/memoryLimit
lrwxrwxrwx    1 root     root            20 Jul 11 21:36 memoryRequest -> ..data/memoryRequest
lrwxrwxrwx    1 root     root            11 Jul 11 21:36 name -> ..data/name
lrwxrwxrwx    1 root     root            16 Jul 11 21:36 namespace -> ..data/namespace
lrwxrwxrwx    1 root     root            10 Jul 11 21:36 uid -> ..data/uid
downward-api-volume-example:/etc/podinfo# cat annotations 
cni.projectcalico.org/containerID="ab58059ec2c7afc061d7c50794cf459ef4ab2702a68f3611f3fe1eb613daa028"
cni.projectcalico.org/podIP="10.244.85.251/32"
cni.projectcalico.org/podIPs="10.244.85.251/32"
kubectl.kubernetes.io/last-applied-configuration="{\"apiVersion\":\"v1\",\"kind\":\"Pod\",\"metadata\":{\"annotations\":{},\"name\":\"downward-api-volume-example\",\"namespace\":\"default\"},\"spec\":{\"containers\":[{\"image\":\"wangyanglinux/myapp:v1.0\",\"name\":\"my-container\",\"resources\":{\"limits\":{\"cpu\":\"1\",\"memory\":\"512Mi\"},\"requests\":{\"cpu\":\"0.5\",\"memory\":\"256Mi\"}},\"volumeMounts\":[{\"mountPath\":\"/etc/podinfo\",\"name\":\"downward-api-volume\"}]}],\"restartPolicy\":\"Never\",\"volumes\":[{\"downwardAPI\":{\"items\":[{\"fieldRef\":{\"fieldPath\":\"metadata.annotations\"},\"path\":\"annotations\"},{\"fieldRef\":{\"fieldPath\":\"metadata.labels\"},\"path\":\"labels\"},{\"fieldRef\":{\"fieldPath\":\"metadata.name\"},\"path\":\"name\"},{\"fieldRef\":{\"fieldPath\":\"metadata.namespace\"},\"path\":\"namespace\"},{\"fieldRef\":{\"fieldPath\":\"metadata.uid\"},\"path\":\"uid\"},{\"path\":\"cpuRequest\",\"resourceFieldRef\":{\"containerName\":\"my-container\",\"resource\":\"requests.cpu\"}},{\"path\":\"memoryRequest\",\"resourceFieldRef\":{\"containerName\":\"my-container\",\"resource\":\"requests.memory\"}},{\"path\":\"cpuLimit\",\"resourceFieldRef\":{\"containerName\":\"my-container\",\"resource\":\"limits.cpu\"}},{\"path\":\"memoryLimit\",\"resourceFieldRef\":{\"containerName\":\"my-container\",\"resource\":\"limits.memory\"}}]},\"name\":\"downward-api-volume\"}]}}\n"
kubernetes.io/config.seen="2025-07-11T21:36:18.116842185+08:00"
kubernetes.io/config.source="api"downward-api-volume-example:/etc/podinfo# cat cpuRequest 
downward-api-volume-example:/etc/podinfo# 
downward-api-volume-example:/etc/podinfo# cat cpuRequest 
downward-api-volume-example:/etc/podinfo# cat memoryRequest 
268435456downward-api-volume-example:/etc/podinfo# cat namespace 
defaultdownward-api-volume-example:/etc/podinfo# 
```

```bash
defaultdownward-api-volume-example:/etc/podinfo# cat labels 
downward-api-volume-example:/etc/podinfo# 
```

```bash
[root@k8s-master01 6]# kubectl get pod --show-labels
NAME                          READY   STATUS    RESTARTS   AGE    LABELS
downward-api-env-example      1/1     Running   0          35m    <none>
downward-api-volume-example   1/1     Running   0          13m    <none>
secret-volume-pod             1/1     Running   0          131m   name=secret-volume
[root@k8s-master01 6]# kubectl label pod downward-api-volume-example domain=tangfire.com
pod/downward-api-volume-example labeled
```

```bash
downward-api-volume-example:/etc/podinfo# cat labels 
domain="tangfire.com"downward-api-volume-example:/etc/podinfo# 
```

æ‰€ä»¥ï¼Œä»¥å·çš„ç»‘å®šæ–¹å¼å¯ä»¥çƒ­æ›´æ–°ï¼Œåªè¦ä½ å¯¹å½“å‰podå‘ç”Ÿçš„ä¸€äº›ä¿®æ”¹ï¼Œéƒ½ä¼šè¢«åé¦ˆåˆ°æ–‡ä»¶å†…éƒ¨çš„å˜åŒ–


### Downward API - volume ç›¸è¾ƒäº env ä¼˜åŠ¿

- ä¼šä¿æŒçƒ­æ›´æ–°çš„ç‰¹æ€§
- ä¼ é€’ä¸€ä¸ªå®¹å™¨çš„èµ„æºå­—æ®µåˆ°å¦ä¸€ä¸ªå®¹å™¨ä¸­


### Downward API - æ‰©å±•

![139](../img/img_139.png)



ä»¥ä¸‹æ˜¯å®Œæ•´çš„ Kubernetes RBAC å’Œ Pod å®šä¹‰ä»£ç ï¼š

### 1. RBAC æƒé™é…ç½® (`1.rbac.yaml`)
```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: test-api-cluster-admin-binding
subjects:
- kind: ServiceAccount
  name: test-api
  namespace: default
roleRef:
  kind: ClusterRole
  name: cluster-admin
  apiGroup: rbac.authorization.k8s.io
```

### 2. Pod å®šä¹‰ (`2.pod.yaml`)
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: curl
spec:
  serviceAccountName: test-api
  containers:
  - name: main
    image: curlimages/curl
    command: ["sleep", "9999"]
```

### 3. å®¹å™¨å†…æ‰§è¡Œçš„ API è®¿é—®å‘½ä»¤
```bash
# è·å–è®¿é—®å‡­è¯
TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
CAPATH="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
NS=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)

# è°ƒç”¨ Kubernetes API
curl -H "Authorization: Bearer $TOKEN" --cacert $CAPATH \
https://kubernetes/api/v1/namespaces/$NS/pods
```

### å…³é”®è¯´æ˜ï¼š
1. **RBAC é…ç½®**ï¼š
  - åˆ›å»ºäº† `ClusterRoleBinding`ï¼Œå°† `cluster-admin` è§’è‰²ç»‘å®šåˆ° `default` å‘½åç©ºé—´ä¸‹çš„ `test-api` æœåŠ¡è´¦å·
  - æˆäºˆäº†æœ€é«˜æƒé™ï¼ˆç”Ÿäº§ç¯å¢ƒåº”éµå¾ªæœ€å°æƒé™åŸåˆ™ï¼‰

2. **Pod é…ç½®**ï¼š
  - ä½¿ç”¨ `tutum/curl` é•œåƒåˆ›å»ºåä¸º `curl` çš„ Pod
  - æŒ‡å®šä½¿ç”¨ `test-api` æœåŠ¡è´¦å·
  - å®¹å™¨å¯åŠ¨åæ‰§è¡Œ `sleep 9999` ä¿æŒè¿è¡Œ

3. **API è®¿é—®æµç¨‹**ï¼š
  - è‡ªåŠ¨æŒ‚è½½çš„æœåŠ¡è´¦å·ä»¤ç‰Œæä¾›è®¤è¯ä¿¡æ¯
  - ä½¿ç”¨ CA è¯ä¹¦éªŒè¯ API Server èº«ä»½
  - é€šè¿‡ Bearer Token è®¤è¯è®¿é—®å½“å‰å‘½åç©ºé—´çš„ Pod åˆ—è¡¨

### ä½¿ç”¨æ­¥éª¤ï¼š


```bash
[root@k8s-master01 14]# vim 1.rbac.yaml
[root@k8s-master01 14]# kubectl apply -f 1.rbac.yaml 
clusterrolebinding.rbac.authorization.k8s.io/test-api-cluster-admin-binding created
[root@k8s-master01 14]# 
[root@k8s-master01 14]# 
[root@k8s-master01 14]# kubectl create sa test-api
serviceaccount/test-api created
[root@k8s-master01 14]# 
[root@k8s-master01 14]# 
[root@k8s-master01 14]# vim 2.pod.yaml
[root@k8s-master01 14]# 
[root@k8s-master01 14]# 
[root@k8s-master01 14]# kubectl apply -f 2.pod.yaml 
pod/curl created
[root@k8s-master01 14]# kubectl get pod
NAME                          READY   STATUS    RESTARTS   AGE
curl                          1/1     Running   0          46s
downward-api-env-example      1/1     Running   0          11h
downward-api-volume-example   1/1     Running   0          11h
secret-volume-pod             1/1     Running   0          13h

[root@k8s-master01 14]# kubectl exec -it curl /bin/sh
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
~ $ 
~ $ TOKEN=$(cat /var/run/secrets/kubernetes.io/serviceaccount/token)
~ $ CAPATH="/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
~ $ NS=$(cat /var/run/secrets/kubernetes.io/serviceaccount/namespace)
~ $ curl -H "Authorization: Bearer $TOKEN" --cacert $CAPATH \
> https://kubernetes/api/v1/namespaces/$NS/pods
```


### Downward API - Kubernetes API æ–‡æ¡£

![140](../img/img_140.png)

```bash
kubectl proxy --port=8080
```

å†èµ·ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œï¼š

```bash
curl localhost:8080/openapi/v2 > k8s-swagger.json
```

```bash
[root@k8s-master01 14]# ls
1.rbac.yaml  2.pod.yaml  k8s-swagger.json
```


```bash
docker run \
  --rm \
  -d \
  -p 80:8080 \
  -e SWAGGER_JSON=/k8s-swagger.json \
  -v $(pwd)/k8s-swagger.json:/k8s-swagger.json \
  swaggerapi/swagger-ui
```


```bash
[root@k8s-master01 14]# docker run \
  --rm \
  -d \
  -p 80:8080 \
  -e SWAGGER_JSON=/k8s-swagger.json \
  -v $(pwd)/k8s-swagger.json:/k8s-swagger.json \
  swaggerapi/swagger-ui
Unable to find image 'swaggerapi/swagger-ui:latest' locally
latest: Pulling from swaggerapi/swagger-ui
fe07684b16b8: Already exists 
3b7062d09e02: Already exists 
fb746e72516f: Already exists 
a9ff9baf1741: Already exists 
2c127093dfc7: Already exists 
63dda2adf85b: Already exists 
b55ed7d7b2de: Already exists 
92971aeb101e: Already exists 
f8757389f534: Pull complete 
9bace28d4d83: Pull complete 
6ca57faa02b3: Pull complete 
857dfce664dd: Pull complete 
6d4a4ac230eb: Pull complete 
d940957079a7: Pull complete 
Digest: sha256:13e9885605519c4ecbe06854e212b10fce703e3c233771de5e58571e459eb9a8
Status: Downloaded newer image for swaggerapi/swagger-ui:latest
6a2654e5a847a0a79aa959e33d994996c8855c4163c178f185702a7b06905d32
```

ç„¶åè®¿é—®ï¼š

![141](../img/img_141.png)







## 05. volume

æ•°æ®çš„æŒä¹…åŒ–æ–¹æ¡ˆ


### Volume - å­˜åœ¨çš„æ„ä¹‰


![142](../img/img_142.png)


![143](../img/img_143.png)



ä»¥ä¸‹æ˜¯é’ˆå¯¹å›¾ç‰‡ä¸­åˆ—å‡ºçš„ Kubernetes æŒä¹…åŒ–å­˜å‚¨å·ï¼ˆPersistent Volumeï¼‰ç±»å‹çš„åˆ†ç±»å’Œè§£é‡Šï¼š

---

### **ä¸€ã€äº‘æœåŠ¡å•†å­˜å‚¨å·**
| ç±»å‹ | è¯´æ˜ | å…¸å‹ä½¿ç”¨åœºæ™¯ |
|------|------|-------------|
| **awsElasticBlockStore** | AWS EBS å—å­˜å‚¨å· | éœ€è¦æŒä¹…åŒ–æ•°æ®çš„ AWS EC2 å®ä¾‹ |
| **azureDisk** | Azure æ‰˜ç®¡ç£ç›˜ | Azure è™šæ‹Ÿæœºä¸Šçš„æŒä¹…åŒ–å­˜å‚¨ |
| **azureFile** | Azure æ–‡ä»¶å­˜å‚¨ï¼ˆSMBï¼‰ | å¤š Pod å…±äº«å­˜å‚¨ï¼ˆå¦‚ WordPress åª’ä½“æ–‡ä»¶ï¼‰ |
| **gcePersistentDisk** | Google Cloud æŒä¹…åŒ–ç£ç›˜ | GCP ä¸Šçš„æŒä¹…åŒ–æ•°æ®å­˜å‚¨ |

---

### **äºŒã€ç½‘ç»œå­˜å‚¨å·**
| ç±»å‹ | è¯´æ˜ | ç‰¹ç‚¹ |
|------|------|------|
| **nfs** | ç½‘ç»œæ–‡ä»¶ç³»ç»Ÿ | å¤šèŠ‚ç‚¹å…±äº«è¯»å†™ï¼Œé€‚åˆé™æ€å†…å®¹ |
| **cephfs** | Ceph åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ | é«˜æ€§èƒ½åˆ†å¸ƒå¼å­˜å‚¨ |
| **glusterfs** | GlusterFS é›†ç¾¤æ–‡ä»¶ç³»ç»Ÿ | å¤§è§„æ¨¡å¯æ‰©å±•å­˜å‚¨ |
| **iscsi** | iSCSI å—å­˜å‚¨ | éœ€è¦è£¸è®¾å¤‡æ˜ å°„çš„åœºæ™¯ |
| **rbd** | Ceph å—è®¾å¤‡ | é«˜æ€§èƒ½å—å­˜å‚¨ï¼ˆå¦‚æ•°æ®åº“ï¼‰ |

---

### **ä¸‰ã€æœ¬åœ°å­˜å‚¨å·**
| ç±»å‹ | è¯´æ˜ | æ³¨æ„äº‹é¡¹ |
|------|------|----------|
| **hostPath** | æŒ‚è½½å®¿ä¸»æœºç›®å½• | ä»…å¼€å‘æµ‹è¯•ç”¨ï¼ˆä¸å®‰å…¨ï¼‰ |
| **local** | æœ¬åœ°æŒä¹…åŒ–å· | éœ€è¦ç»“åˆèŠ‚ç‚¹äº²å’Œæ€§è°ƒåº¦ |
| **emptyDir** | ä¸´æ—¶ç©ºç›®å½• | Pod åˆ é™¤åæ•°æ®é”€æ¯ |

---

### **å››ã€ç‰¹æ®Šç”¨é€”å­˜å‚¨å·**
| ç±»å‹ | è¯´æ˜ | å…¸å‹ç”¨ä¾‹ |
|------|------|---------|
| **secret** | æŒ‚è½½æ•æ„Ÿä¿¡æ¯ï¼ˆå¦‚å¯†ç ï¼‰ | æ•°æ®åº“å‡­è¯ |
| **downwardAPI** | å°† Pod å…ƒæ•°æ®æŒ‚è½½ä¸ºæ–‡ä»¶ | è·å– Pod åç§°/IP ç­‰ |
| **gitRepo** | å…‹éš† Git ä»“åº“åˆ°å· | é…ç½®æ–‡ä»¶åŠ¨æ€æ›´æ–° |
| **projected** | åˆå¹¶å¤šä¸ªå­˜å‚¨æºï¼ˆå¦‚ secret+downwardAPIï¼‰ | å¤æ‚é…ç½®ç®¡ç† |

---

### **äº”ã€ä¼ä¸šçº§å­˜å‚¨æ–¹æ¡ˆ**
| ç±»å‹ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| **portworxVolume** | Portworx å®¹å™¨åŸç”Ÿå­˜å‚¨ | æœ‰çŠ¶æ€å®¹å™¨ç¼–æ’ |
| **storageos** | StorageOS è½¯ä»¶å®šä¹‰å­˜å‚¨ | ä½å»¶è¿ŸæŒä¹…åŒ–å­˜å‚¨ |
| **vsphereVolume** | VMware vSphere å­˜å‚¨ | ä¼ä¸šè™šæ‹ŸåŒ–ç¯å¢ƒ |
| **scaleIO** | EMC ScaleIO å­˜å‚¨ | è¶…èåˆåŸºç¡€æ¶æ„ |

---

### **å…­ã€å·²å¼ƒç”¨/è¿‡æ—¶ç±»å‹**
| ç±»å‹ | æ›¿ä»£æ–¹æ¡ˆ | å¼ƒç”¨åŸå›  |
|------|---------|---------|
| **flocker** | ä½¿ç”¨ CSI é©±åŠ¨ | é¡¹ç›®å·²åœæ­¢ç»´æŠ¤ |
| **quobyte** | æ”¹ç”¨ CSI é©±åŠ¨ | ç¤¾åŒºæ”¯æŒæœ‰é™ |
| **fc** (Fibre Channel) | ä½¿ç”¨ CSI é©±åŠ¨ | é…ç½®å¤æ‚ |

---

### **é€‰æ‹©å»ºè®®**
1. **äº‘ç¯å¢ƒ**ï¼šä¼˜å…ˆä½¿ç”¨äº‘å‚å•†åŸç”Ÿå­˜å‚¨ï¼ˆå¦‚ AWS EBSï¼‰
2. **å…±äº«å­˜å‚¨**ï¼šé€‰æ‹© `nfs` æˆ– `cephfs`
3. **æ•æ„Ÿæ•°æ®**ï¼šä½¿ç”¨ `secret` æˆ– `configMap`
4. **æœªæ¥å…¼å®¹æ€§**ï¼šä¼˜å…ˆé€‰æ‹© **CSI**ï¼ˆContainer Storage Interfaceï¼‰é©±åŠ¨

> æ³¨ï¼šç”Ÿäº§ç¯å¢ƒæ¨èé€šè¿‡ **StorageClass** åŠ¨æ€åˆ†é…å­˜å‚¨ï¼Œè€Œéç›´æ¥ä½¿ç”¨ PVã€‚


### MFS


### **ä»€ä¹ˆæ˜¯ MFSï¼Ÿ**
**MFSï¼ˆMoose File Systemï¼‰** æ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿï¼Œä¸“ä¸ºå¤§è§„æ¨¡æ•°æ®å­˜å‚¨å’Œé«˜å¯ç”¨æ€§è®¾è®¡ã€‚å®ƒç±»ä¼¼äº **HDFSï¼ˆHadoop DFSï¼‰** æˆ– **CephFS**ï¼Œä½†æ›´æ³¨é‡æ˜“ç”¨æ€§å’Œ POSIX å…¼å®¹æ€§ï¼ˆå³å¯ä»¥åƒæ™®é€šæ–‡ä»¶ç³»ç»Ÿä¸€æ ·ä½¿ç”¨ï¼‰ã€‚

---

## **1. MFS çš„æ ¸å¿ƒç‰¹ç‚¹**
| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **åˆ†å¸ƒå¼å­˜å‚¨** | æ•°æ®åˆ†æ•£åœ¨å¤šä¸ªæœåŠ¡å™¨ä¸Šï¼Œæé«˜å¯é æ€§å’Œæ€§èƒ½ |
| **é«˜å¯ç”¨æ€§** | æ”¯æŒä¸»å¤‡å…ƒæ•°æ®æœåŠ¡å™¨ï¼ˆMaster Serverï¼‰ï¼Œé¿å…å•ç‚¹æ•…éšœ |
| **POSIX å…¼å®¹** | åƒæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿä¸€æ ·ä½¿ç”¨ï¼ˆæ”¯æŒ `ls`ã€`cp`ã€`mv` ç­‰å‘½ä»¤ï¼‰ |
| **åŠ¨æ€æ‰©å±•** | å¯åœ¨çº¿æ·»åŠ å­˜å‚¨èŠ‚ç‚¹ï¼ˆChunk Serverï¼‰ï¼Œæ— éœ€åœæœº |
| **æ•°æ®å†—ä½™** | æ”¯æŒå‰¯æœ¬æœºåˆ¶ï¼ˆç±»ä¼¼ RAIDï¼‰ï¼Œé˜²æ­¢æ•°æ®ä¸¢å¤± |
| **å¿«ç…§åŠŸèƒ½** | å¯åˆ›å»ºæ–‡ä»¶ç³»ç»Ÿå¿«ç…§ï¼Œç”¨äºå¤‡ä»½æˆ–æ¢å¤ |

---

## **2. MFS çš„æ¶æ„**
MFS é‡‡ç”¨ **ä¸»ä»æ¶æ„**ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹ç»„ä»¶ï¼š
### **(1) ç®¡ç†æœåŠ¡å™¨ï¼ˆMaster Serverï¼‰**
- **ä½œç”¨**ï¼šå­˜å‚¨æ–‡ä»¶çš„å…ƒæ•°æ®ï¼ˆå¦‚æ–‡ä»¶åã€ç›®å½•ç»“æ„ã€æƒé™ç­‰ï¼‰ã€‚
- **é«˜å¯ç”¨**ï¼šå¯é…ç½® **Metalogger**ï¼ˆå…ƒæ•°æ®å¤‡ä»½æœåŠ¡å™¨ï¼‰å’Œ **Shadow Master**ï¼ˆå½±å­ä¸»æœåŠ¡å™¨ï¼‰å®ç°æ•…éšœè½¬ç§»ã€‚

### **(2) æ•°æ®å­˜å‚¨èŠ‚ç‚¹ï¼ˆChunk Serverï¼‰**
- **ä½œç”¨**ï¼šå®é™…å­˜å‚¨æ–‡ä»¶æ•°æ®ï¼ˆåˆ†æˆå¤šä¸ª **Chunk**ï¼Œé»˜è®¤ 64MB/å—ï¼‰ã€‚
- **æ‰©å±•æ€§**ï¼šå¯åŠ¨æ€æ·»åŠ èŠ‚ç‚¹ï¼Œå­˜å‚¨å®¹é‡éšèŠ‚ç‚¹å¢åŠ è€Œå¢é•¿ã€‚

### **(3) å®¢æˆ·ç«¯ï¼ˆClientï¼‰**
- **ä½œç”¨**ï¼šé€šè¿‡ **FUSE**ï¼ˆç”¨æˆ·æ€æ–‡ä»¶ç³»ç»Ÿï¼‰æŒ‚è½½ MFSï¼Œåƒæœ¬åœ°ç£ç›˜ä¸€æ ·è®¿é—®ã€‚
- **åè®®æ”¯æŒ**ï¼šæ”¯æŒ NFSã€SMBã€FTP ç­‰ã€‚

![MFS æ¶æ„å›¾](https://moosefs.com/static/images/mfs-architecture.png)

---

## **3. MFS çš„å…¸å‹åº”ç”¨åœºæ™¯**
1. **å¤§æ•°æ®å­˜å‚¨**
  - æ›¿ä»£ HDFSï¼Œç”¨äº Hadoop/Spark ç­‰åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ã€‚
2. **åª’ä½“æ–‡ä»¶æ‰˜ç®¡**
  - å­˜å‚¨å›¾ç‰‡ã€è§†é¢‘ç­‰å¤§æ–‡ä»¶ï¼ˆå¦‚ CDN åç«¯ï¼‰ã€‚
3. **è™šæ‹ŸåŒ–å­˜å‚¨**
  - ä¸º KVM/VMware æä¾›å…±äº«å­˜å‚¨ã€‚
4. **å¤‡ä»½ä¸å®¹ç¾**
  - åˆ©ç”¨å¿«ç…§åŠŸèƒ½å®ç°æ•°æ®ä¿æŠ¤ã€‚

---

## **4. MFS vs å…¶ä»–åˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ**
| æ–‡ä»¶ç³»ç»Ÿ | ç‰¹ç‚¹ | é€‚ç”¨åœºæ™¯ |
|----------|------|----------|
| **MFS** | POSIX å…¼å®¹ï¼Œæ˜“éƒ¨ç½² | é€šç”¨å­˜å‚¨ã€åª’ä½“åº“ |
| **HDFS** | é€‚åˆæ‰¹å¤„ç†ï¼Œä¸æ”¯æŒéšæœºå†™ | Hadoop ç”Ÿæ€ |
| **CephFS** | é«˜æ‰©å±•æ€§ï¼Œä½†é…ç½®å¤æ‚ | äº‘åŸç”Ÿå­˜å‚¨ |
| **GlusterFS** | æ— å…ƒæ•°æ®æœåŠ¡å™¨ï¼Œæ€§èƒ½è¾ƒä½ | å…±äº«æ–‡ä»¶å­˜å‚¨ |

---

## **5. å¿«é€Ÿä½“éªŒ MFS**
### **æ­¥éª¤ 1ï¼šå®‰è£… Master Server**
```bash
wget -O /etc/yum.repos.d/MooseFS.repo https://ppa.moosefs.com/src/moosefs-3-el7.repo
yum install moosefs-master moosefs-metalogger moosefs-chunkserver
systemctl start moosefs-master
```

### **æ­¥éª¤ 2ï¼šæŒ‚è½½ MFS å®¢æˆ·ç«¯**
```bash
yum install moosefs-client
mkdir /mnt/mfs
mfsmount /mnt/mfs -H mfsmaster
```

### **æ­¥éª¤ 3ï¼šéªŒè¯**
```bash
df -h | grep mfs  # æŸ¥çœ‹æŒ‚è½½æƒ…å†µ
echo "Hello MFS" > /mnt/mfs/test.txt  # æµ‹è¯•å†™å…¥
```

---

## **6. æ³¨æ„äº‹é¡¹**
- **æ€§èƒ½ç“¶é¢ˆ**ï¼šMaster Server æ˜¯å•ç‚¹ï¼Œè¶…å¤§è§„æ¨¡é›†ç¾¤å»ºè®®ç”¨ Cephã€‚
- **å®‰å…¨æ€§**ï¼šé»˜è®¤æœªåŠ å¯†ï¼Œç”Ÿäº§ç¯å¢ƒéœ€é…ç½® SSL/TLSã€‚
- **ç¤¾åŒºæ”¯æŒ**ï¼šMFS å¼€æºç‰ˆæ›´æ–°è¾ƒæ…¢ï¼Œä¼ä¸šéœ€æ±‚å¯è€ƒè™‘å•†ä¸šç‰ˆï¼ˆMooseFS Proï¼‰ã€‚



### Volume - emptyDir - æ¦‚å¿µ


![144](../img/img_144.png)


### Volume - emptyDir - åˆ›å»ºä½¿ç”¨

![145](../img/img_145.png)


#### 15.pod.yaml


```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-emptydir-pod
  namespace: default
spec:
  containers:
    - name: myapp
      image: nginx:alpine  
      ports:
        - containerPort: 80
      volumeMounts:
        - name: logs-volume
          mountPath: /var/log/nginx  # æ ‡å‡†Nginxæ—¥å¿—è·¯å¾„
    - name: busybox
      image: busybox:latest  
      command: ["/bin/sh","-c","touch /logs/access.log && tail -f /logs/access.log"]
      volumeMounts:
        - name: logs-volume
          mountPath: /logs
  volumes:
    - name: logs-volume
      emptyDir: {}
```

è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨ `emptyDir` å·å®ç°å®¹å™¨é—´å…±äº«æ—¥å¿—çš„ Kubernetes Pod é…ç½®ï¼Œæˆ‘æ¥ä¸ºæ‚¨è¯¦ç»†è§£é‡Šï¼š

### é…ç½®è§£æï¼š
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-emptydir-pod  # Podåç§°
  namespace: default         # éƒ¨ç½²åœ¨defaultå‘½åç©ºé—´
spec:
  containers:
  - name: myapp             # ç¬¬ä¸€ä¸ªå®¹å™¨ï¼šNginxæœåŠ¡
    image: nginx:alpine     # ä½¿ç”¨å®˜æ–¹Nginxé•œåƒ
    ports:
    - containerPort: 80     # æš´éœ²80ç«¯å£
    volumeMounts:
    - name: logs-volume     # æŒ‚è½½å­˜å‚¨å·
      mountPath: /var/log/nginx  # Nginxé»˜è®¤æ—¥å¿—ç›®å½•
      
  - name: busybox           # ç¬¬äºŒä¸ªå®¹å™¨ï¼šæ—¥å¿—ç›‘æ§
    image: busybox:latest    # ä½¿ç”¨å®˜æ–¹BusyBoxé•œåƒ
    command: ["/bin/sh","-c","touch /logs/access.log && tail -f /logs/access.log"] 
    volumeMounts:
    - name: logs-volume     # æŒ‚è½½åŒä¸€ä¸ªå­˜å‚¨å·
      mountPath: /logs      # æŒ‚è½½åˆ°ä¸åŒè·¯å¾„

  volumes:
  - name: logs-volume       # å®šä¹‰å­˜å‚¨å·
    emptyDir: {}            # ä¸´æ—¶ç©ºç›®å½•å·
```

### æ ¸å¿ƒæœºåˆ¶ï¼š
1. **emptyDir å·**ï¼š
  - ç”Ÿå‘½å‘¨æœŸä¸Podç»‘å®šï¼ˆPodåˆ é™¤åæ•°æ®æ¶ˆå¤±ï¼‰
  - ä¸¤ä¸ªå®¹å™¨é€šè¿‡æŒ‚è½½åŒä¸€ä¸ªå·å®ç°æ–‡ä»¶å…±äº«
  - é€‚åˆä¸´æ—¶æ•°æ®äº¤æ¢åœºæ™¯

2. **æ—¥å¿—æµå·¥ä½œåŸç†**ï¼š
  - Nginxå®¹å™¨å°†æ—¥å¿—å†™å…¥ `/var/log/nginx/access.log`
  - ç”±äºæŒ‚è½½äº†åŒä¸€ä¸ªå·ï¼Œå®é™…å†™å…¥çš„æ˜¯ `emptyDir` çš„å­˜å‚¨ç©ºé—´
  - BusyBoxå®¹å™¨ä» `/logs/access.log` è¯»å–ç›¸åŒæ–‡ä»¶
  - `tail -f` å‘½ä»¤å®ç°æ—¥å¿—å®æ—¶ç›‘æ§

3. **è·¯å¾„å·®å¼‚å¤„ç†**ï¼š
  - è™½ç„¶æŒ‚è½½ç‚¹ä¸åŒï¼ˆ`/var/log/nginx` å’Œ `/logs`ï¼‰
  - ä½†æŒ‡å‘çš„æ˜¯åŒä¸€ä¸ªç‰©ç†å­˜å‚¨ä½ç½®

### å…¸å‹ä½¿ç”¨åœºæ™¯ï¼š
- å¼€å‘è°ƒè¯•æ—¶å®æ—¶æŸ¥çœ‹å®¹å™¨æ—¥å¿—
- ä¸´æ—¶æ€§çš„å®¹å™¨é—´æ•°æ®äº¤æ¢
- ä¸éœ€è¦æŒä¹…åŒ–çš„ä¸­é—´æ•°æ®å¤„ç†

### æ³¨æ„äº‹é¡¹ï¼š
1. ç”Ÿäº§ç¯å¢ƒå¦‚éœ€æŒä¹…åŒ–å­˜å‚¨ï¼Œåº”æ”¹ç”¨ `persistentVolumeClaim`
2. `emptyDir` é»˜è®¤ä½¿ç”¨èŠ‚ç‚¹å­˜å‚¨ä»‹è´¨ï¼ˆå¯èƒ½å½±å“IOæ€§èƒ½ï¼‰
3. å¯ä»¥é€šè¿‡ `emptyDir.medium: Memory` æŒ‡å®šä½¿ç”¨å†…å­˜ï¼ˆä¸´æ—¶æ€§æ›´é«˜ï¼‰

æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤éªŒè¯æ—¥å¿—å…±äº«ï¼š
```bash
kubectl exec volume-emptydir-pod -c myapp -- ls /var/log/nginx
kubectl exec volume-emptydir-pod -c busybox -- ls /logs
```

è¿™ä¸ªæ–¹æ¡ˆæ¯”é€šè¿‡ `kubectl logs` å‘½ä»¤æŸ¥çœ‹æ—¥å¿—çš„ä¼˜åŠ¿åœ¨äºå¯ä»¥å®æ—¶ç›‘æ§æ—¥å¿—å˜åŒ–ï¼Œé€‚åˆè°ƒè¯•åœºæ™¯ã€‚



```bash
[root@k8s-master01 7]# vim 15.pod.yaml
[root@k8s-master01 7]# kubectl apply -f 15.pod.yaml 
pod/volume-emptydir-pod created
[root@k8s-master01 7]# 
[root@k8s-master01 7]# kubectl get pod
NAME                          READY   STATUS    RESTARTS   AGE
curl                          1/1     Running   0          100m
downward-api-env-example      1/1     Running   0          13h
downward-api-volume-example   1/1     Running   0          13h
secret-volume-pod             1/1     Running   0          15h
volume-emptydir-pod           2/2     Running   0          60s
```

```bash
[root@k8s-master01 7]# kubectl get pod -o wide
NAME                          READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES
curl                          1/1     Running   0          108m    10.244.58.216   k8s-node02   <none>           <none>
downward-api-env-example      1/1     Running   0          13h     10.244.58.213   k8s-node02   <none>           <none>
downward-api-volume-example   1/1     Running   0          13h     10.244.85.251   k8s-node01   <none>           <none>
secret-volume-pod             1/1     Running   0          15h     10.244.58.212   k8s-node02   <none>           <none>
volume-emptydir-pod           2/2     Running   0          8m31s   10.244.58.214   k8s-node02   <none>           <none>
[root@k8s-master01 7]# while true;
> do
> curl 10.244.58.214
> done
```







å†èµ·ä¸€ä¸ªç»ˆç«¯ï¼š

```bash
[root@k8s-master01 14]# kubectl get pod
NAME                          READY   STATUS    RESTARTS   AGE
curl                          1/1     Running   0          104m
downward-api-env-example      1/1     Running   0          13h
downward-api-volume-example   1/1     Running   0          13h
secret-volume-pod             1/1     Running   0          15h
volume-emptydir-pod           2/2     Running   0          4m54s
[root@k8s-master01 14]# kubectl logs volume-emptydir-pod -c busybox
192.168.120.11 - - [12/Jul/2025:02:45:53 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:45:55 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:45:56 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:45:57 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:45:58 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:45:59 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:00 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:01 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:02 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:03 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:04 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:05 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:06 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:07 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:08 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:09 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:10 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:46:11 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
```

```bash
[root@k8s-master01 14]# kubectl exec -it volume-emptydir-pod -c myapp /bin/sh
kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl exec [POD] -- [COMMAND] instead.
/ # cd /var
/var # cd log
/var/log # ls
nginx
/var/log # cd nginx
/var/log/nginx # ls
access.log  error.log
/var/log/nginx # 
```


### æŸ¥çœ‹podçš„uid

```bash
[root@k8s-master01 7]# kubectl get pod -o wide
NAME                          READY   STATUS    RESTARTS   AGE    IP              NODE         NOMINATED NODE   READINESS GATES
volume-emptydir-pod           2/2     Running   0          39m    10.244.58.214   k8s-node02   <none>           <none>
[root@k8s-master01 7]# 
[root@k8s-master01 7]# 
[root@k8s-master01 7]# 
[root@k8s-master01 7]# kubectl get pod volume-emptydir-pod -o yaml | grep uid
  uid: 5628286e-2fba-4fa1-9101-37d0e515d779
```
ç„¶ååˆ°node02èŠ‚ç‚¹

æ‰§è¡Œï¼š

```bash
[root@k8s-node02 docker]# cd /var/lib/kubelet/pods
[root@k8s-node02 pods]# ls
2e02ae83-5e9e-4f13-bd50-31eda9ba034b  d435644c-9464-4878-87b6-5de57384822b
5628286e-2fba-4fa1-9101-37d0e515d779  d8f842b0-a567-4572-95cd-e2d8dd0ca939
71845854-3a1a-4e5e-8ea3-be4821ecb7e2  e5656dc1-a051-46a1-ad96-402228f761d9
[root@k8s-node02 pods]# cd 5628286e-2fba-4fa1-9101-37d0e515d779
[root@k8s-node02 5628286e-2fba-4fa1-9101-37d0e515d779]# ls
containers  etc-hosts  plugins  volumes
[root@k8s-node02 5628286e-2fba-4fa1-9101-37d0e515d779]# yum -y install tree
Last metadata expiration check: 0:37:10 ago on Sat Jul 12 12:39:55 2025.
Dependencies resolved.
=========================================================================================
 Package          Architecture       Version                    Repository          Size
=========================================================================================
Installing:
 tree             x86_64             1.8.0-10.el9               baseos              55 k

Transaction Summary
=========================================================================================
Install  1 Package

Total download size: 55 k
Installed size: 113 k
Downloading Packages:
tree-1.8.0-10.el9.x86_64.rpm                             107 kB/s |  55 kB     00:00    
-----------------------------------------------------------------------------------------
Total                                                    106 kB/s |  55 kB     00:00     
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                                 1/1 
  Installing       : tree-1.8.0-10.el9.x86_64                                        1/1 
  Running scriptlet: tree-1.8.0-10.el9.x86_64                                        1/1 
  Verifying        : tree-1.8.0-10.el9.x86_64                                        1/1 

Installed:
  tree-1.8.0-10.el9.x86_64                                                               

Complete!
[root@k8s-node02 5628286e-2fba-4fa1-9101-37d0e515d779]# tree .
.
â”œâ”€â”€ containers
â”‚Â Â  â”œâ”€â”€ busybox
â”‚Â Â  â”‚Â Â  â””â”€â”€ bee3a6d5
â”‚Â Â  â””â”€â”€ myapp
â”‚Â Â      â””â”€â”€ bb4a9bcd
â”œâ”€â”€ etc-hosts
â”œâ”€â”€ plugins
â”‚Â Â  â””â”€â”€ kubernetes.io~empty-dir
â”‚Â Â      â”œâ”€â”€ logs-volume
â”‚Â Â      â”‚Â Â  â””â”€â”€ ready
â”‚Â Â      â””â”€â”€ wrapped_kube-api-access-jkzlt
â”‚Â Â          â””â”€â”€ ready
â””â”€â”€ volumes
    â”œâ”€â”€ kubernetes.io~empty-dir
    â”‚Â Â  â””â”€â”€ logs-volume
    â”‚Â Â      â”œâ”€â”€ access.log
    â”‚Â Â      â””â”€â”€ error.log
    â””â”€â”€ kubernetes.io~projected
        â””â”€â”€ kube-api-access-jkzlt
            â”œâ”€â”€ ca.crt -> ..data/ca.crt
            â”œâ”€â”€ namespace -> ..data/namespace
            â””â”€â”€ token -> ..data/token

12 directories, 10 files
[root@k8s-node02 5628286e-2fba-4fa1-9101-37d0e515d779]# cd volumes/
[root@k8s-node02 volumes]# cd kubernetes.io~empty-dir/
[root@k8s-node02 kubernetes.io~empty-dir]# cd logs-volume/
[root@k8s-node02 logs-volume]# ls
access.log  error.log
[root@k8s-node02 logs-volume]# echo "tangfire216" >> access.log 
```



```bash
[root@k8s-node02 logs-volume]# kubectl logs volume-emptydir-pod -c busybox 
192.168.120.11 - - [12/Jul/2025:02:49:45 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:49:45 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
192.168.120.11 - - [12/Jul/2025:02:49:45 +0000] "GET / HTTP/1.1" 200 615 "-" "curl/7.76.1" "-"
tangfire216
```




### Volume - emptyDir - å…±äº«å†…å­˜

#### 16.pod.yaml

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-emptydir-mem
  namespace: default
spec:
  containers:
    - name: myapp
      image: nginx:1.25
      ports:
        - containerPort: 80
      resources:
        limits:
          cpu: "1"
          memory: "1024Mi"
        requests:
          cpu: "1"
          memory: "1024Mi"
      volumeMounts:
        - name: mem-volume
          mountPath: /data
  volumes:
    - name: mem-volume
      emptyDir:
        medium: Memory
        sizeLimit: 500Mi
```


### **Kubernetes Pod é…ç½®è§£æ**
è¿™ä¸ª YAML æ–‡ä»¶å®šä¹‰äº†ä¸€ä¸ªä½¿ç”¨ **å†…å­˜ä¸´æ—¶å·ï¼ˆemptyDirï¼‰** çš„ Podï¼Œä»¥ä¸‹æ˜¯é€éƒ¨åˆ†è§£é‡Šï¼š

---

#### **1. åŸºç¡€ä¿¡æ¯**
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: volume-emptydir-mem  # Podåç§°
  namespace: default          # éƒ¨ç½²åœ¨defaultå‘½åç©ºé—´
```
- **ä½œç”¨**ï¼šå®šä¹‰ä¸€ä¸ªåä¸º `volume-emptydir-mem` çš„ Podï¼Œä½äºé»˜è®¤å‘½åç©ºé—´ã€‚

---

#### **2. å®¹å™¨é…ç½®**
```yaml
spec:
  containers:
    - name: myapp                     # å®¹å™¨åç§°
      image: wangyanglinux/myapp:v1.0 # ä½¿ç”¨ç§æœ‰é•œåƒ
      ports:
        - containerPort: 80           # æš´éœ²80ç«¯å£
```
- **åŠŸèƒ½**ï¼šå®¹å™¨è¿è¡Œ `myapp` æœåŠ¡ï¼Œç›‘å¬ 80 ç«¯å£ã€‚

---

#### **3. èµ„æºé™åˆ¶**
```yaml
resources:
  limits:
    cpu: "1"         # æœ€å¤šä½¿ç”¨1æ ¸CPU
    memory: "1024Mi" # æœ€å¤šä½¿ç”¨1GBå†…å­˜
  requests:
    cpu: "1"         # è‡³å°‘éœ€è¦1æ ¸CPU
    memory: "1024Mi" # è‡³å°‘éœ€è¦1GBå†…å­˜
```
- **å…³é”®ç‚¹**ï¼š
  - `limits` æ˜¯ç¡¬æ€§é™åˆ¶ï¼ˆè¶…è¿‡ä¼šè¢«ç»ˆæ­¢ï¼‰
  - `requests` æ˜¯è°ƒåº¦ä¾æ®ï¼ˆK8s æ ¹æ®æ­¤å€¼åˆ†é…èµ„æºï¼‰
  - è¿™é‡Œè®¾ç½®ä¸ºç›¸åŒå€¼ï¼Œè¡¨ç¤ºè¦æ±‚ç‹¬å èµ„æºã€‚

---

#### **4. å†…å­˜ä¸´æ—¶å·ï¼ˆemptyDirï¼‰**
```yaml
volumeMounts:
  - name: mem-volume
    mountPath: /data  # æŒ‚è½½åˆ°å®¹å™¨å†…çš„/dataè·¯å¾„

volumes:
  - name: mem-volume
    emptyDir:
      medium: Memory   # ä½¿ç”¨å†…å­˜è€Œéç£ç›˜
      sizeLimit: 500Mi # é™åˆ¶å·å¤§å°ä¸º500MB
```
- **æ ¸å¿ƒç‰¹æ€§**ï¼š
  - **å†…å­˜å­˜å‚¨**ï¼šæ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ï¼Œè¯»å†™é€Ÿåº¦æå¿«ï¼Œä½† **Pod é‡å¯åæ•°æ®ä¸¢å¤±**ã€‚
  - **å®¹é‡é™åˆ¶**ï¼šå·å¤§å°ä¸è¶…è¿‡ 500MBï¼ˆè¶…è¿‡ä¼šè§¦å‘ evictionï¼‰ã€‚
  - **å…±äº«æ€§**ï¼šå¯è¢«åŒä¸€ Pod å†…çš„å¤šä¸ªå®¹å™¨æŒ‚è½½ï¼ˆæœ¬ä¾‹ä¸­ä»… `myapp` å®¹å™¨ä½¿ç”¨ï¼‰ã€‚

---

### **å…¸å‹åº”ç”¨åœºæ™¯**
1. **ä¸´æ—¶ç¼“å­˜**
  - ä¾‹å¦‚ç¼“å­˜è®¡ç®—ç»“æœï¼ŒåŠ é€Ÿåç»­å¤„ç†ã€‚
2. **æ•æ„Ÿæ•°æ®å¤„ç†**
  - å†…å­˜æ•°æ®ä¸ä¼šè½ç›˜ï¼Œé€‚åˆå¤„ç†å¯†ç ç­‰æ•æ„Ÿä¿¡æ¯ã€‚
3. **é«˜æ€§èƒ½è¯»å†™**
  - é¿å…ç£ç›˜ IO ç“¶é¢ˆï¼ˆå¦‚å®æ—¶æ•°æ®åˆ†æï¼‰ã€‚

---

### **æ³¨æ„äº‹é¡¹**
1. **æ•°æ®æ˜“å¤±æ€§**
  - Pod å´©æºƒæˆ–é‡å¯ä¼šå¯¼è‡´æ•°æ®ä¸¢å¤±ï¼Œ**ä¸å¯ç”¨äºæŒä¹…åŒ–å­˜å‚¨**ã€‚
2. **èµ„æºç›‘æ§**
  - å†…å­˜å·ä¼šè®¡å…¥å®¹å™¨çš„å†…å­˜ä½¿ç”¨é‡ï¼Œéœ€ç¡®ä¿ `sizeLimit` â‰¤ å®¹å™¨å†…å­˜é™åˆ¶ã€‚
3. **ç”Ÿäº§å»ºè®®**
  - æ›¿æ¢ç§æœ‰é•œåƒ `wangyanglinux/myapp:v1.0` ä¸ºå…¬å…±é•œåƒï¼ˆå¦‚ `nginx:alpine`ï¼‰ã€‚
  - å¦‚éœ€æŒä¹…åŒ–ï¼Œæ”¹ç”¨ `persistentVolumeClaim`ã€‚

---

### **æ“ä½œéªŒè¯**
```bash
# 1. åˆ›å»ºPod
kubectl apply -f pod.yaml

# 2. è¿›å…¥å®¹å™¨æŸ¥çœ‹æŒ‚è½½ç‚¹
kubectl exec volume-emptydir-mem -- ls /data

# 3. ç›‘æ§èµ„æºä½¿ç”¨
kubectl top pod volume-emptydir-mem
```



### Volume - hostPath - æ¦‚å¿µ


![146](../img/img_146.png)

### Volume - hostPath - ç±»å‹

![147](../img/img_147.png)


### Volume - hostPath - æ³¨æ„

![148](../img/img_148.png)



### Volume - hostPath å®éªŒ



#### 17.pod.yaml

```bash
apiVersion: v1
kind: Pod
metadata:
  name: hostpath-pod
spec:
  containers:
    - name: myapp
      image: nginx:1.25
      volumeMounts:
        - name: test-volume
          mountPath: /test-pd
  volumes:
    - name: test-volume
      hostPath:
        path: /test
        type: Directory
```


```bash
[root@k8s-master01 7]# kubectl get pod
NAME                          READY   STATUS              RESTARTS       AGE
curl                          1/1     Running             1 (160m ago)   5h27m
downward-api-env-example      1/1     Running             0              17h
downward-api-volume-example   1/1     Running             0              16h
hostpath-pod                  0/1     ContainerCreating   0              19m
secret-volume-pod             1/1     Running             0              18h
volume-emptydir-mem           1/1     Running             0              50m
volume-emptydir-pod           2/2     Running             0              3h47m
[root@k8s-master01 7]# kubectl describe pod hostpath-pod
Name:             hostpath-pod
Namespace:        default
Priority:         0
Service Account:  default
Node:             k8s-node02/192.168.120.13
Start Time:       Sat, 12 Jul 2025 14:06:49 +0800
Labels:           <none>
Annotations:      <none>
Status:           Pending
IP:               
IPs:              <none>
Containers:
  myapp:
    Container ID:   
    Image:          linux:1.25
    Image ID:       
    Port:           <none>
    Host Port:      <none>
    State:          Waiting
      Reason:       ContainerCreating
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /test-pd from test-volume (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-v7g4h (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   False 
  Initialized                 True 
  Ready                       False 
  ContainersReady             False 
  PodScheduled                True 
Volumes:
  test-volume:
    Type:          HostPath (bare host directory volume)
    Path:          /test
    HostPathType:  Directory
  kube-api-access-v7g4h:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason       Age                 From               Message
  ----     ------       ----                ----               -------
  Normal   Scheduled    19m                 default-scheduler  Successfully assigned default/hostpath-pod to k8s-node02
  Warning  FailedMount  64s (x17 over 19m)  kubelet            MountVolume.SetUp failed for volume "test-volume" : hostPath type check failed: /test is not a directory
```


æ— æ³•åˆ›å»ºæˆåŠŸï¼Œå› ä¸ºå½“å‰æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ ¹æœ¬æ²¡æœ‰testç›®å½•


```bash
[root@k8s-master01 7]# kubectl delete -f 17.pod.yaml 
pod "hostpath-pod" deleted
```

å»èŠ‚ç‚¹node1,èŠ‚ç‚¹node2æ‰§è¡Œï¼š

```bash
[root@k8s-node01 pods]# cd ~
[root@k8s-node01 ~]# mkdir /test

[root@k8s-node01 ~]# hostname > /test/index.html
```

```bash
[root@k8s-node02 logs-volume]# cd ~
[root@k8s-node02 ~]# mkdir /test

[root@k8s-node02 ~]# hostname > /test/index.html
```



```bash
[root@k8s-master01 7]# kubectl apply -f 17.pod.yaml 
pod/hostpath-pod created
[root@k8s-master01 7]# kubectl get pod -o wide
NAME                          READY   STATUS    RESTARTS        AGE     IP              NODE         NOMINATED NODE   READINESS GATES
hostpath-pod                  1/1     Running   0               9s      10.244.58.220   k8s-node02   <none>           <none>

[root@k8s-master01 7]# kubectl exec -it hostpath-pod -- /bin/sh
# 
# cd /test-pd    
# ls
index.html
# cat index.html        
k8s-node02
```



## 06. pv/pvc


å­˜å‚¨ä¸­çš„å„å¸å…¶èŒ

### PV/PVC


![149](../img/img_149.png)


### PV/PVC - å…³è”æ¡ä»¶


![150](../img/img_150.png)


### PV/PVC - å›æ”¶ç­–ç•¥

![151](../img/img_151.png)

### PV/PVC - çŠ¶æ€


![152](../img/img_152.png)



### PV/PVC - PVCä¿æŠ¤

![153](../img/img_153.png)



### PV/PVC - StatefulSet - éƒ¨ç½²


#### å®‰è£…NFSæœåŠ¡å™¨

åœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šæ‰§è¡Œï¼š

##### å®‰è£… NFS æœåŠ¡ç«¯è½¯ä»¶åŒ…

```bash
yum install -y nfs-utils rpcbind
```

æ­£å¸¸æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šåœ¨ä¸€ä¸ªç‹¬ç«‹çš„æœºå™¨ä¸Šéƒ¨ç½²è¿™ä¸ªNFSæœåŠ¡å™¨ï¼Œè¿™è¾¹ä¸ºäº†ç®€å•èµ·è§ï¼Œå°±ç›´æ¥åœ¨master01ä¸Šéƒ¨ç½²äº†

åœ¨master01èŠ‚ç‚¹æ˜¯æ‰§è¡Œï¼š

##### åˆ›å»ºå…±äº«ç›®å½•å¹¶è®¾ç½®æƒé™

```bash
mkdir -p /nfsdata
chmod 666 /nfsdata
chown nobody /nfsdata
```
##### é…ç½® NFS å…±äº«ï¼ˆ/etc/exportsï¼‰


```bash
cat > /etc/exports <<EOF
/nfsdata *(rw,no_root_squash,no_all_squash,sync)
EOF
```


```bash
[root@k8s-master01 7]# cd /nfsdata/
[root@k8s-master01 nfsdata]# ls
[root@k8s-master01 nfsdata]# mkdir {1..10}
[root@k8s-master01 nfsdata]# ls
1  10  2  3  4  5  6  7  8  9
[root@k8s-master01 nfsdata]# echo "1" > 1/index.html
[root@k8s-master01 nfsdata]# echo "2" > 2/index.html
[root@k8s-master01 nfsdata]# echo "3" > 3/index.html
[root@k8s-master01 nfsdata]# echo "4" > 4/index.html
[root@k8s-master01 nfsdata]# echo "5" > 5/index.html
[root@k8s-master01 nfsdata]# echo "6" > 6/index.html
[root@k8s-master01 nfsdata]# echo "7" > 7/index.html
[root@k8s-master01 nfsdata]# echo "8" > 8/index.html
[root@k8s-master01 nfsdata]# echo "9" > 9/index.html
[root@k8s-master01 nfsdata]# echo "10" > 10/index.html
[root@k8s-master01 nfsdata]# cat 1/index.html 
1
```

```bash
[root@k8s-master01 nfsdata]# vim /etc/exports
```

æ”¹æˆè¿™æ ·ï¼š

```bash
/nfsdata/1 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/2 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/3 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/4 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/5 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/6 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/7 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/8 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/9 *(rw,no_root_squash,no_all_squash,sync)
/nfsdata/10 *(rw,no_root_squash,no_all_squash,sync)
```

```bash
systemctl restart rpcbind
systemctl restart nfs-server
```

```bash
[root@k8s-master01 nfsdata]# systemctl restart rpcbind
systemctl restart nfs-server
[root@k8s-master01 nfsdata]# showmount -e 192.168.120.11
Export list for 192.168.120.11:
/nfsdata/10 *
/nfsdata/9  *
/nfsdata/8  *
/nfsdata/7  *
/nfsdata/6  *
/nfsdata/5  *
/nfsdata/4  *
/nfsdata/3  *
/nfsdata/2  *
/nfsdata/1  *
```


åœ¨node1èŠ‚ç‚¹ä¸Šæ‰§è¡Œï¼š

```bash
[root@k8s-node01 ~]# mkdir /nfstest
[root@k8s-node01 ~]# mount -t nfs 192.168.120.11:/nfsdata/1 /nfstest/
[root@k8s-node01 ~]# cd /nfstest/
[root@k8s-node01 nfstest]# ls
index.html
[root@k8s-node01 nfstest]# cat index.html 
1
[root@k8s-node01 nfstest]# echo "tangfire" >> index.html
[root@k8s-node01 nfstest]# cat index.html 
1
tangfire
```

ç„¶åæˆ‘ä»¬å†çœ‹çœ‹master01èŠ‚ç‚¹ï¼š

```bash
[root@k8s-master01 nfsdata]# cat 1/index.html 
1
tangfire
```

ç„¶åæˆ‘ä»¬åœ¨node1èŠ‚ç‚¹ä¸Šæ‰§è¡Œï¼š

```bash
[root@k8s-node01 nfstest]# umount /nfstest/
umount.nfs4: /nfstest: device is busy
[root@k8s-node01 nfstest]# cd 
[root@k8s-node01 ~]# umount /nfstest/
```


#### éƒ¨ç½²PV

#### pv.yaml

```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv1
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /nfsdata/1
    server: 192.168.120.11

---


apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv2
spec:
  capacity:
    storage: 0.9Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /nfsdata/2
    server: 192.168.120.11

---


apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv3
spec:
  capacity:
    storage: 1.2Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /nfsdata/3
    server: 192.168.120.11

---


apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv4
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /nfsdata/4
    server: 192.168.120.11

---


apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv5
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteMany
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs
  nfs:
    path: /nfsdata/5
    server: 192.168.120.11

---


apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv6
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: nfs1
  nfs:
    path: /nfsdata/6
    server: 192.168.120.11

---


apiVersion: v1
kind: PersistentVolume
metadata:
  name: nfspv7
spec:
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Retain
  storageClassName: nfs
  nfs:
    path: /nfsdata/7
    server: 192.168.120.11


```


```bash
[root@k8s-master01 18]# kubectl apply -f pv.yaml 
persistentvolume/nfspv1 created
persistentvolume/nfspv2 created
persistentvolume/nfspv3 created
persistentvolume/nfspv4 created
persistentvolume/nfspv5 created
persistentvolume/nfspv6 created
persistentvolume/nfspv7 created

[root@k8s-master01 18]# kubectl get pv
NAME     CAPACITY         ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
nfspv1   1Gi              RWO            Recycle          Available           nfs            <unset>                          25s
nfspv2   966367641600m    RWO            Recycle          Available           nfs            <unset>                          25s
nfspv3   1288490188800m   RWO            Recycle          Available           nfs            <unset>                          25s
nfspv4   1Gi              RWO            Recycle          Available           nfs            <unset>                          25s
nfspv5   1Gi              RWX            Recycle          Available           nfs            <unset>                          25s
nfspv6   1Gi              RWO            Recycle          Available           nfs1           <unset>                          25s
nfspv7   1Gi              RWO            Retain           Available           nfs            <unset>                          25s
```









#### åˆ›å»ºæœåŠ¡å¹¶ä½¿ç”¨PVC


#### statefulSet.yaml

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None  # Headless Service æ ‡è¯†
  selector:
    app: nginx

---

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  serviceName: "nginx"
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
        - name: nginx
          image: nginx:alpine  # ä½¿ç”¨å®˜æ–¹Nginxé•œåƒæ›¿ä»£ç§æœ‰é•œåƒ
          ports:
            - containerPort: 80
              name: web
          volumeMounts:
            - name: www
              mountPath: /usr/share/nginx/html  # è°ƒæ•´ä¸ºæ ‡å‡†Nginxè·¯å¾„
  volumeClaimTemplates:
    - metadata:
        name: www
      spec:
        accessModes: [ "ReadWriteOnce" ]
        storageClassName: "nfs"
        resources:
          requests:
            storage: 1Gi
```


```bash
[root@k8s-master01 18]# kubectl apply -f statefulSet.yaml 
service/nginx created
statefulset.apps/web created
[root@k8s-master01 18]# kubectl get pod
NAME    READY   STATUS    RESTARTS   AGE
web-0   1/1     Running   0          105s
web-1   1/1     Running   0          103s
web-2   1/1     Running   0          101s
```


#### æŸ¥çœ‹k8sä¸­DNSæœåŠ¡å™¨çš„VIP

åœ¨ Kubernetes ä¸­ï¼ŒDNS æœåŠ¡çš„ VIPï¼ˆè™šæ‹Ÿ IPï¼‰é€šå¸¸æ˜¯ **CoreDNS** æˆ– **kube-dns** æœåŠ¡çš„ ClusterIPã€‚ä»¥ä¸‹æ˜¯æŸ¥çœ‹æ–¹æ³•ï¼š

---

### **1. ç¡®è®¤ DNS æœåŠ¡åç§°**
```bash
kubectl get svc -n kube-system | grep -E 'kube-dns|CoreDNS'
```
è¾“å‡ºç¤ºä¾‹ï¼š
```
NAME       TYPE        CLUSTER-IP     PORT(S)
coredns    ClusterIP   10.96.0.10     53/UDP,53/TCP
```
- **`10.96.0.10`** å°±æ˜¯ DNS æœåŠ¡çš„ VIPï¼ˆClusterIPï¼‰ã€‚

---

### **2. æŸ¥çœ‹ DNS æœåŠ¡çš„è¯¦ç»†é…ç½®**
```bash
kubectl describe svc coredns -n kube-system
```
å…³é”®è¾“å‡ºï¼š
```
IP:                       10.96.0.10
Port:                      dns  53/UDP
TargetPort:                53/UDP
Endpoints:                 10.244.0.5:53,10.244.0.6:53
```
- **`IP: 10.96.0.10`** æ˜¯ VIPï¼ˆæ‰€æœ‰ DNS è¯·æ±‚éƒ½ä¼šå‘å¾€æ­¤ IPï¼‰ã€‚
- **`Endpoints`** æ˜¯å®é™…è¿è¡Œ CoreDNS çš„ Pod IPã€‚

---

### **3. æŸ¥çœ‹ Pod çš„ DNS é…ç½®**
```bash
kubectl exec -it <ä»»æ„Podåç§°> -- cat /etc/resolv.conf
```
è¾“å‡ºç¤ºä¾‹ï¼š
```
nameserver 10.96.0.10
search default.svc.cluster.local svc.cluster.local cluster.local
```
- **`nameserver 10.96.0.10`** å°±æ˜¯é›†ç¾¤çš„ DNS VIPã€‚

---

### **4. ç›´æ¥æµ‹è¯• DNS è§£æ**
```bash
# è¿›å…¥ä¸€ä¸ªä¸´æ—¶Podæµ‹è¯•
kubectl run -it --rm --image=busybox:latest test --restart=Never -- nslookup kubernetes.default
```
è¾“å‡ºç¤ºä¾‹ï¼š
```
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
```
- **`Server: 10.96.0.10`** å³ä¸º DNS æœåŠ¡çš„ VIPã€‚

---

### **5. ç‰¹æ®Šæƒ…å†µè¯´æ˜**
1. **å¦‚æœä½¿ç”¨è‡ªå®šä¹‰ DNS**ï¼š
  - æ£€æŸ¥ `kubelet` é…ç½®ä¸­çš„ `--cluster-dns` å‚æ•°ï¼š
    ```bash
    ps aux | grep kubelet | grep cluster-dns
    ```
2. **å¦‚æœ VIP æ— æ³•è®¿é—®**ï¼š
  - æ£€æŸ¥ CoreDNS Pod æ˜¯å¦æ­£å¸¸è¿è¡Œï¼š
    ```bash
    kubectl get pods -n kube-system -l k8s-app=kube-dns
    ```

---

### **æ€»ç»“**
| é¡¹ç›®               | å…¸å‹å€¼          | æŸ¥çœ‹æ–¹å¼                      |
|--------------------|----------------|-----------------------------|
| **DNS VIP**        | `10.96.0.10`   | `kubectl get svc -n kube-system` |
| **DNS è§£ææµ‹è¯•**   | `nslookup`     | ä¸´æ—¶ Pod æµ‹è¯•                  |
| **è‡ªå®šä¹‰é…ç½®**     | `kubelet` å‚æ•° | æ£€æŸ¥èŠ‚ç‚¹æœåŠ¡é…ç½®                |




---

```bash
[root@k8s-master01 18]# kubectl get pod
NAME    READY   STATUS    RESTARTS   AGE
web-0   1/1     Running   0          105s
web-1   1/1     Running   0          103s
web-2   1/1     Running   0          101s
[root@k8s-master01 18]# 
[root@k8s-master01 18]# kubectl get svc
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
kubernetes   ClusterIP   10.0.0.1     <none>        443/TCP   8d
nginx        ClusterIP   None         <none>        80/TCP    3m51s
[root@k8s-master01 18]# kubectl get endpoints
NAME         ENDPOINTS                                            AGE
kubernetes   192.168.120.11:6443                                  8d
nginx        10.244.58.222:80,10.244.85.254:80,10.244.85.255:80   4m10s
[root@k8s-master01 18]# kubectl get svc -n kube-system | grep -E 'kube-dns|CoreDNS'
kube-dns       ClusterIP   10.0.0.10      <none>        53/UDP,53/TCP,9153/TCP   8d
[root@k8s-master01 18]# dig -t A nginx.default.svc.cluster.local. @10.0.0.10

; <<>> DiG 9.16.23-RH <<>> -t A nginx.default.svc.cluster.local. @10.0.0.10
;; global options: +cmd
;; Got answer:
;; WARNING: .local is reserved for Multicast DNS
;; You are currently testing what happens when an mDNS query is leaked to DNS
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 11981
;; flags: qr aa rd; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1
;; WARNING: recursion requested but not available

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
; COOKIE: 96df3d5dbd1006f9 (echoed)
;; QUESTION SECTION:
;nginx.default.svc.cluster.local. IN	A

;; ANSWER SECTION:
nginx.default.svc.cluster.local. 30 IN	A	10.244.85.255
nginx.default.svc.cluster.local. 30 IN	A	10.244.58.222
nginx.default.svc.cluster.local. 30 IN	A	10.244.85.254

;; Query time: 56 msec
;; SERVER: 10.0.0.10#53(10.0.0.10)
;; WHEN: Sat Jul 12 19:21:18 CST 2025
;; MSG SIZE  rcvd: 213

[root@k8s-master01 18]# kubectl get pod -o wide
NAME    READY   STATUS    RESTARTS   AGE     IP              NODE         NOMINATED NODE   READINESS GATES
web-0   1/1     Running   0          8m57s   10.244.85.254   k8s-node01   <none>           <none>
web-1   1/1     Running   0          8m55s   10.244.58.222   k8s-node02   <none>           <none>
web-2   1/1     Running   0          8m53s   10.244.85.255   k8s-node01   <none>           <none>
```

æ— å¤´æœåŠ¡ä¼šå°†å½“å‰æˆ‘ä»¬çš„æ ‡ç­¾é€‰æ‹©å™¨åŒ¹é…åˆ°çš„podï¼Œæ·»åŠ åˆ°å½“å‰çš„DNSè§£æç»“æœé‡Œå»




```bash
[root@k8s-master01 18]# kubectl get statefulSet
NAME   READY   AGE
web    3/3     12m
[root@k8s-master01 18]# kubectl scale statefulSet web --replicas=10
statefulset.apps/web scaled
[root@k8s-master01 18]# kubectl get pod
NAME    READY   STATUS    RESTARTS   AGE
web-0   1/1     Running   0          12m
web-1   1/1     Running   0          12m
web-2   1/1     Running   0          12m
web-3   1/1     Running   0          5s
web-4   0/1     Pending   0          3s

[root@k8s-master01 18]# kubectl describe pod web-4
Name:             web-4
Namespace:        default
Priority:         0
Service Account:  default
Node:             <none>
Labels:           app=nginx
                  apps.kubernetes.io/pod-index=4
                  controller-revision-hash=web-6578c54df4
                  statefulset.kubernetes.io/pod-name=web-4
Annotations:      <none>
Status:           Pending
IP:               
IPs:              <none>
Controlled By:    StatefulSet/web
Containers:
  nginx:
    Image:        nginx:alpine
    Port:         80/TCP
    Host Port:    0/TCP
    Environment:  <none>
    Mounts:
      /usr/share/nginx/html from www (rw)
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-wzkdn (ro)
Conditions:
  Type           Status
  PodScheduled   False 
Volumes:
  www:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  www-web-4
    ReadOnly:   false
  kube-api-access-wzkdn:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age                    From               Message
  ----     ------            ----                   ----               -------
  Warning  FailedScheduling  2m24s (x2 over 7m47s)  default-scheduler  0/3 nodes are available: pod has unbound immediate PersistentVolumeClaims. preemption: 0/3 nodes are available: 3 Preemption is not helpful for scheduling.
[root@k8s-master01 18]# kubectl get pv
NAME     CAPACITY         ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
nfspv1   1Gi              RWO            Recycle          Bound       default/www-web-1   nfs            <unset>                          34m
nfspv2   966367641600m    RWO            Recycle          Available                       nfs            <unset>                          34m
nfspv3   1288490188800m   RWO            Recycle          Bound       default/www-web-3   nfs            <unset>                          34m
nfspv4   1Gi              RWO            Recycle          Bound       default/www-web-2   nfs            <unset>                          34m
nfspv5   1Gi              RWX            Recycle          Available                       nfs            <unset>                          34m
nfspv6   1Gi              RWO            Recycle          Available                       nfs1           <unset>                          34m
nfspv7   1Gi              RWO            Retain           Bound       default/www-web-0   nfs            <unset>                          34m
```


```bash
[root@k8s-master01 18]# kubectl get pod -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
web-0   1/1     Running   0          32m   10.244.85.254   k8s-node01   <none>           <none>
web-1   1/1     Running   0          32m   10.244.58.222   k8s-node02   <none>           <none>
web-2   1/1     Running   0          32m   10.244.85.255   k8s-node01   <none>           <none>
web-3   1/1     Running   0          20m   10.244.58.221   k8s-node02   <none>           <none>
web-4   0/1     Pending   0          20m   <none>          <none>       <none>           <none>
[root@k8s-master01 18]# curl 10.244.85.254
7
[root@k8s-master01 18]# kubectl get pvc
NAME        STATUS    VOLUME   CAPACITY         ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
www-web-0   Bound     nfspv7   1Gi              RWO            nfs            <unset>                 34m
www-web-1   Bound     nfspv1   1Gi              RWO            nfs            <unset>                 33m
www-web-2   Bound     nfspv4   1Gi              RWO            nfs            <unset>                 33m
www-web-3   Bound     nfspv3   1288490188800m   RWO            nfs            <unset>                 21m
www-web-4   Pending                                            nfs            <unset>                 21m
```



```bash
[root@k8s-master01 18]# kubectl exec -it web-0 -- /bin/sh
/ # cd /usr/share/nginx/html
/usr/share/nginx/html # ls
index.html
/usr/share/nginx/html # echo "tangfire" >> index.html
/usr/share/nginx/html # exit
[root@k8s-master01 18]# curl 10.244.85.254
7
tangfire
[root@k8s-master01 18]# kubectl delete pod web-0
pod "web-0" deleted
[root@k8s-master01 18]# kubectl get pod -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
web-0   1/1     Running   0          11s   10.244.85.192   k8s-node01   <none>           <none>
web-1   1/1     Running   0          37m   10.244.58.222   k8s-node02   <none>           <none>
web-2   1/1     Running   0          37m   10.244.85.255   k8s-node01   <none>           <none>
web-3   1/1     Running   0          26m   10.244.58.221   k8s-node02   <none>           <none>
web-4   0/1     Pending   0          26m   <none>          <none>       <none>           <none>
[root@k8s-master01 18]# curl 10.244.85.192
7
tangfire
```



![154](../img/img_154.png)


```bash
[root@k8s-master01 18]# kubectl delete -f statefulSet.yaml 
service "nginx" deleted
statefulset.apps "web" deleted
[root@k8s-master01 18]# kubectl get pod
No resources found in default namespace.
[root@k8s-master01 18]# kubectl get pv
NAME     CAPACITY         ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
nfspv1   1Gi              RWO            Recycle          Bound       default/www-web-1   nfs            <unset>                          62m
nfspv2   966367641600m    RWO            Recycle          Available                       nfs            <unset>                          62m
nfspv3   1288490188800m   RWO            Recycle          Bound       default/www-web-3   nfs            <unset>                          62m
nfspv4   1Gi              RWO            Recycle          Bound       default/www-web-2   nfs            <unset>                          62m
nfspv5   1Gi              RWX            Recycle          Available                       nfs            <unset>                          62m
nfspv6   1Gi              RWO            Recycle          Available                       nfs1           <unset>                          62m
nfspv7   1Gi              RWO            Retain           Bound       default/www-web-0   nfs            <unset>                          62m
[root@k8s-master01 18]# kubectl get pvc
NAME        STATUS    VOLUME   CAPACITY         ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
www-web-0   Bound     nfspv7   1Gi              RWO            nfs            <unset>                 48m
www-web-1   Bound     nfspv1   1Gi              RWO            nfs            <unset>                 48m
www-web-2   Bound     nfspv4   1Gi              RWO            nfs            <unset>                 48m
www-web-3   Bound     nfspv3   1288490188800m   RWO            nfs            <unset>                 36m
www-web-4   Pending                                            nfs            <unset>                 36m
[root@k8s-master01 18]# kubectl apply -f statefulSet.yaml 
service/nginx created
statefulset.apps/web created
[root@k8s-master01 18]# kubectl get pod -o wide
NAME    READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
web-0   1/1     Running   0          9s    10.244.58.223   k8s-node02   <none>           <none>
web-1   1/1     Running   0          8s    10.244.85.193   k8s-node01   <none>           <none>
web-2   1/1     Running   0          6s    10.244.58.225   k8s-node02   <none>           <none>
[root@k8s-master01 18]# curl 10.244.58.223
7
tangfire
```


```bash
[root@k8s-master01 18]# kubectl delete -f statefulSet.yaml 
service "nginx" deleted
statefulset.apps "web" deleted
[root@k8s-master01 18]# kubectl delete pvc --all
persistentvolumeclaim "www-web-0" deleted
persistentvolumeclaim "www-web-1" deleted
persistentvolumeclaim "www-web-2" deleted
persistentvolumeclaim "www-web-3" deleted
persistentvolumeclaim "www-web-4" deleted
[root@k8s-master01 18]# kubectl get pv
NAME     CAPACITY         ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
nfspv1   1Gi              RWO            Recycle          Released    default/www-web-1   nfs            <unset>                          68m
nfspv2   966367641600m    RWO            Recycle          Available                       nfs            <unset>                          68m
nfspv3   1288490188800m   RWO            Recycle          Failed      default/www-web-3   nfs            <unset>                          68m
nfspv4   1Gi              RWO            Recycle          Failed      default/www-web-2   nfs            <unset>                          68m
nfspv5   1Gi              RWX            Recycle          Available                       nfs            <unset>                          68m
nfspv6   1Gi              RWO            Recycle          Available                       nfs1           <unset>                          68m
nfspv7   1Gi              RWO            Retain           Released    default/www-web-0   nfs            <unset>                          68m
```

---

#### PersistentVolume (PV) ä» `Released` çŠ¶æ€æ¢å¤ä¸º `Available` çŠ¶æ€


åœ¨ Kubernetes ä¸­ï¼Œå°† PersistentVolume (PV) ä» `Released` çŠ¶æ€æ¢å¤ä¸º `Available` çŠ¶æ€ï¼Œéœ€è¦æ‰‹åŠ¨æ¸…ç†å…¶ç»‘å®šå…³ç³»ã€‚ä»¥ä¸‹æ˜¯å…·ä½“æ“ä½œæ­¥éª¤å’Œä»£ç ç¤ºä¾‹ï¼š

---

### **1. æŸ¥çœ‹å½“å‰ PV çŠ¶æ€**
```bash
kubectl get pv
```
è¾“å‡ºç¤ºä¾‹ï¼š
```
NAME      CAPACITY  STATUS      CLAIM             STORAGECLASS
pv-nfs    1Gi       Released    default/www-web-0 nfs
```

---

### **2. æ‰‹åŠ¨é‡Šæ”¾ PVï¼ˆå…³é”®æ­¥éª¤ï¼‰**
ç¼–è¾‘ PV é…ç½®ï¼Œåˆ é™¤ `claimRef` å­—æ®µï¼ˆè¿™æ˜¯å¯¼è‡´çŠ¶æ€ä¸º Released çš„æ ¹æºï¼‰ï¼š
```bash
kubectl edit pv <pv-name>
```
æ‰¾åˆ°å¹¶åˆ é™¤ä»¥ä¸‹éƒ¨åˆ†ï¼š
```yaml
spec:
  claimRef:
    apiVersion: v1
    kind: PersistentVolumeClaim
    name: www-web-0  # åŸç»‘å®šçš„PVCåç§°
    namespace: default
```

---

### **3. å¼ºåˆ¶å›æ”¶ PVï¼ˆå¦‚æœä»ä¸ç”Ÿæ•ˆï¼‰**
å¦‚æœ PV çš„å›æ”¶ç­–ç•¥æ˜¯ `Retain`ï¼Œéœ€æ‰‹åŠ¨æ¸…ç†æ•°æ®å¹¶é‡ç½®çŠ¶æ€ï¼š
```bash
kubectl patch pv <pv-name> -p '{"spec":{"claimRef":null}}'
```

---

### **4. éªŒè¯çŠ¶æ€å˜æ›´**
```bash
kubectl get pv <pv-name>
```
é¢„æœŸè¾“å‡ºï¼š
```
NAME      CAPACITY  STATUS      CLAIM  STORAGECLASS
pv-nfs    1Gi       Available          nfs
```

---

### **å®Œæ•´æ“ä½œç¤ºä¾‹**
å‡è®¾ PV åç§°ä¸º `pv-nfs`ï¼š
```bash
# 1. æŸ¥çœ‹PV
kubectl get pv pv-nfs -o yaml

# 2. è§£é™¤ç»‘å®š
kubectl patch pv pv-nfs --type=json -p '[{"op":"remove","path":"/spec/claimRef"}]'

# 3. éªŒè¯
kubectl get pv pv-nfs
```

---

### **æ ¹æœ¬åŸå› åˆ†æ**
| çŠ¶æ€ | è§¦å‘æ¡ä»¶ | è§£å†³æ–¹æ¡ˆ |
|------|----------|----------|
| `Released` | PVC è¢«åˆ é™¤ï¼Œä½† PV ä»ä¿ç•™ç»‘å®šè®°å½• | åˆ é™¤ `claimRef` |
| `Failed` | å­˜å‚¨åç«¯æ•…éšœ | æ£€æŸ¥å­˜å‚¨ç³»ç»Ÿæ—¥å¿— |

---

### **æ³¨æ„äº‹é¡¹**
1. **æ•°æ®å®‰å…¨**ï¼š
  - å¦‚æœ PV ä¸­åŸæœ‰æ•°æ®é‡è¦ï¼Œæ“ä½œå‰å…ˆå¤‡ä»½ï¼ˆå°¤å…¶æ˜¯å›æ”¶ç­–ç•¥ä¸º `Delete` æ—¶ï¼‰ã€‚
2. **StatefulSet å…³è”**ï¼š
  - ç¡®ä¿å¯¹åº”çš„ StatefulSet å·²åˆ é™¤æˆ–ç¼©å®¹ï¼Œå¦åˆ™æ–° PVC ä¼šå†æ¬¡ç»‘å®šã€‚
3. **NFS å­˜å‚¨**ï¼š
  - å¦‚æœæ˜¯ NFS PVï¼Œéœ€ç¡®ä¿æœåŠ¡å™¨å…±äº«ç›®å½• `/data/nfs` å·²æ¸…ç©ºæˆ–å¯å¤ç”¨ã€‚


---

### PV/PVC - StatefulSet - ç‰¹æ€§


![155](../img/img_155.png)



## 07. storageClass

ä¸€ç§åŠ¨æ€çš„ç”³è¯·å­˜å‚¨çš„æœºåˆ¶


![156](../img/img_156.png)


### storageClassæ¦‚å¿µ


![157](../img/img_157.png)


### nfs-client-provisioner

![158](../img/img_158.png)


#### æ­å»ºNFSæœåŠ¡å™¨

ç•¥ï¼Œä¸Šæ–‡å·²ç»æ­å»º

#### éƒ¨ç½²nfs-client-provisioner

```bash
[root@k8s-master01 18]# vim /etc/exports
```


åŠ å…¥è¿™ä¸ªï¼š

```bash
/nfsdata/share *(rw,no_root_squash,no_all_squash,sync)
```

```bash
[root@k8s-master01 18]# mkdir -p /nfsdata/share
[root@k8s-master01 18]# chown -R nobody /nfsdata/share/
[root@k8s-master01 18]# systemctl restart nfs-server
[root@k8s-master01 18]# systemctl enable nfs-server
[root@k8s-master01 18]# systemctl enable rpcbind

[root@k8s-master01 18]# showmount -e 192.168.120.11
Export list for 192.168.120.11:
/nfsdata/share *
/nfsdata/10    *
/nfsdata/9     *
/nfsdata/8     *
/nfsdata/7     *
/nfsdata/6     *
/nfsdata/5     *
/nfsdata/4     *
/nfsdata/3     *
/nfsdata/2     *
/nfsdata/1     *
```

#### éƒ¨ç½²nfs-client-provisioner

#### deployment.yaml

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nfs-client-provisioner
  namespace: nfs-storageclass
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nfs-client-provisioner
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: nfs-client-provisioner
    spec:
      serviceAccountName: nfs-client-provisioner
      containers:
      - name: nfs-client-provisioner
        image: dyrnq/nfs-subdir-external-provisioner:v4.0.2
        volumeMounts:
        - name: nfs-client-root
          mountPath: /persistentvolumes
        env:
        - name: PROVISIONER_NAME
          value: k8s-sigs.io/nfs-subdir-external-provisioner
        - name: NFS_SERVER
          value: 192.168.120.11
        - name: NFS_PATH
          value: /nfsdata/share
      volumes:
      - name: nfs-client-root
        nfs:
          server: 192.168.120.11
          path: /nfsdata/share

```

#### rbac.yaml

```yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nfs-client-provisioner
  namespace: nfs-storageclass
---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nfs-client-provisioner-runner
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["persistentvolumes"]
  verbs: ["get", "list", "watch", "create", "delete"]
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "list", "watch", "update"]
- apiGroups: ["storage.k8s.io"]
  resources: ["storageclasses"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create", "update", "patch"]
---

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: run-nfs-client-provisioner
subjects:
- kind: ServiceAccount
  name: nfs-client-provisioner
  namespace: nfs-storageclass
roleRef:
  kind: ClusterRole
  name: nfs-client-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
---

apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: nfs-storageclass
rules:
- apiGroups: [""]
  resources: ["endpoints"]
  verbs: ["get", "list", "watch", "create", "update", "patch"]
---

apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: leader-locking-nfs-client-provisioner
  namespace: nfs-storageclass
subjects:
- kind: ServiceAccount
  name: nfs-client-provisioner
  namespace: nfs-storageclass
roleRef:
  kind: Role
  name: leader-locking-nfs-client-provisioner
  apiGroup: rbac.authorization.k8s.io
```


#### storageclass.yaml

```yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: nfs-client
  namespace: nfs-storageclass
provisioner: k8s-sigs.io/nfs-subdir-external-provisioner
parameters:
  pathPattern: "${.PVC.namespace}/${.PVC.name}"
  onDelete: "delete"
```





#### åˆ›å»ºåå­—ç©ºé—´

```bash
kubectl create ns nfs-storageclass
```

```bash
[root@k8s-master01 19]# vim deployment.yaml
[root@k8s-master01 19]# 
[root@k8s-master01 19]# vim rbac.yaml
[root@k8s-master01 19]# 
[root@k8s-master01 19]# vim storageclass.yaml
[root@k8s-master01 19]# 
[root@k8s-master01 19]# kubectl apply -f ../19/
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner created
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner created
storageclass.storage.k8s.io/nfs-client created
Error from server (NotFound): error when creating "../19/deployment.yaml": namespaces "nfs-storageclass" not found
Error from server (NotFound): error when creating "../19/rbac.yaml": namespaces "nfs-storageclass" not found
Error from server (NotFound): error when creating "../19/rbac.yaml": namespaces "nfs-storageclass" not found
Error from server (NotFound): error when creating "../19/rbac.yaml": namespaces "nfs-storageclass" not found

[root@k8s-master01 19]# kubectl create ns nfs-storageclass
namespace/nfs-storageclass created
[root@k8s-master01 19]# kubectl apply -f ../19/
deployment.apps/nfs-client-provisioner created
serviceaccount/nfs-client-provisioner created
clusterrole.rbac.authorization.k8s.io/nfs-client-provisioner-runner unchanged
clusterrolebinding.rbac.authorization.k8s.io/run-nfs-client-provisioner unchanged
role.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
rolebinding.rbac.authorization.k8s.io/leader-locking-nfs-client-provisioner created
storageclass.storage.k8s.io/nfs-client unchanged
```


```bash
[root@k8s-master01 19]# kubectl get pod -A
NAMESPACE          NAME                                       READY   STATUS              RESTARTS     AGE
default            recycler-for-nfspv3                        0/1     Terminating         0            33s
default            recycler-for-nfspv4                        0/1     ContainerCreating   0            18s
kube-system        calico-kube-controllers-558d465845-d8msr   1/1     Running             1            9d
kube-system        calico-node-59bdv                          1/1     Running             6 (8d ago)   9d
kube-system        calico-node-f7pk5                          1/1     Running             1            9d
kube-system        calico-node-wn5vm                          1/1     Running             1            9d
kube-system        calico-typha-5b56944f9b-t8n4m              1/1     Running             1            9d
kube-system        coredns-857d9ff4c9-drmqk                   1/1     Running             3 (8d ago)   9d
kube-system        coredns-857d9ff4c9-jknr4                   1/1     Running             3 (8d ago)   9d
kube-system        etcd-k8s-master01                          1/1     Running             3 (8d ago)   9d
kube-system        kube-apiserver-k8s-master01                1/1     Running             3 (8d ago)   9d
kube-system        kube-controller-manager-k8s-master01       1/1     Running             3 (8d ago)   9d
kube-system        kube-proxy-275ph                           1/1     Running             0            3d19h
kube-system        kube-proxy-n89sz                           1/1     Running             0            3d19h
kube-system        kube-proxy-pmv8z                           1/1     Running             0            3d19h
kube-system        kube-scheduler-k8s-master01                1/1     Running             3 (8d ago)   9d
nfs-storageclass   nfs-client-provisioner-8c5b9b749-z8v7p     1/1     Running             0            8m41s
[root@k8s-master01 19]# kubectl get storageclass
NAME         PROVISIONER                                   RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
nfs-client   k8s-sigs.io/nfs-subdir-external-provisioner   Delete          Immediate           false                  11h
```



#### æµ‹è¯•Pod

#### sctest.yaml

```yaml
---
# PersistentVolumeClaim é…ç½®
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: test-claim
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Mi
  storageClassName: nfs-client

---
# Pod é…ç½®
apiVersion: v1
kind: Pod
metadata:
  name: test-pod
spec:
  containers:
  - name: nginx-container
    image: nginx:1.25  # ä½¿ç”¨å®˜æ–¹å…¬å…±é•œåƒæ›¿ä»£ç§æœ‰é•œåƒ
    volumeMounts:
    - name: nfs-pvc
      mountPath: "/usr/share/nginx/html"  # ä¿®æ”¹ä¸ºæ ‡å‡†è·¯å¾„
  restartPolicy: Never
  volumes:
  - name: nfs-pvc
    persistentVolumeClaim:
      claimName: test-claim
```


```bash
[root@k8s-master01 19]# vim sctest.yaml
[root@k8s-master01 19]# 
[root@k8s-master01 19]# 
[root@k8s-master01 19]# kubectl apply -f sctest.yaml 
persistentvolumeclaim/test-claim created
pod/test-pod created
[root@k8s-master01 19]# kubectl get pvc
NAME         STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
test-claim   Bound    pvc-0e77feef-020f-493e-9912-b4f049ba1668   1Mi        RWX            nfs-client     <unset>                 60s
[root@k8s-master01 19]# kubectl get pv
NAME                                       CAPACITY         ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM                STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
nfspv2                                     966367641600m    RWO            Recycle          Available                        nfs            <unset>                          14h
nfspv3                                     1288490188800m   RWO            Recycle          Failed      default/www-web-3    nfs            <unset>                          14h
nfspv4                                     1Gi              RWO            Recycle          Failed      default/www-web-2    nfs            <unset>                          14h
nfspv5                                     1Gi              RWX            Recycle          Available                        nfs            <unset>                          14h
nfspv6                                     1Gi              RWO            Recycle          Available                        nfs1           <unset>                          14h
nfspv7                                     1Gi              RWO            Retain           Released    default/www-web-0    nfs            <unset>                          14h
pvc-0e77feef-020f-493e-9912-b4f049ba1668   1Mi              RWX            Delete           Bound       default/test-claim   nfs-client     <unset>                          71s
```



```bash
[root@k8s-master01 19]# kubectl get pod
NAME                  READY   STATUS             RESTARTS   AGE
recycler-for-nfspv4   0/1     ImagePullBackOff   0          3m35s
test-pod              1/1     Running            0          12m
[root@k8s-master01 19]# kubectl exec -it test-pod -- /bin/sh
# 
# cd /usr/share/nginx/html    
# ls 
# hostname > /usr/share/nginx/html/hostname.html  
# echo "123" > index.html
# ls
hostname.html  index.html
# exit
[root@k8s-master01 19]# 
[root@k8s-master01 19]# 
[root@k8s-master01 19]# kubectl get pod -o wide
NAME       READY   STATUS    RESTARTS   AGE   IP              NODE         NOMINATED NODE   READINESS GATES
test-pod   1/1     Running   0          14m   10.244.58.244   k8s-node02   <none>           <none>
[root@k8s-master01 19]# curl 10.244.58.244
123
[root@k8s-master01 19]# cd /nfsdata/share/default/test-claim
[root@k8s-master01 test-claim]# ls
hostname.html  index.html
[root@k8s-master01 test-claim]# cat index.html 
123
[root@k8s-master01 test-claim]# echo "good morning" >> index.html
[root@k8s-master01 test-claim]# curl 10.244.58.244
123
good morning
```



## 08. æ’æ›²

é‡Šæ”¾é”®å…¥é€Ÿåº¦

### å‘½ä»¤è¡¥å…¨

![159](../img/img_159.png)

```bash
[root@k8s-master01 19]# yum -y install bash-completion
Last metadata expiration check: 3:26:45 ago on Sun Jul 13 06:40:40 2025.
Dependencies resolved.
=========================================================================================
 Package                     Architecture    Version               Repository       Size
=========================================================================================
Installing:
 bash-completion             noarch          1:2.11-5.el9          baseos          291 k
Installing dependencies:
 libpkgconf                  x86_64          1.7.3-10.el9          baseos           35 k
 pkgconf                     x86_64          1.7.3-10.el9          baseos           40 k
 pkgconf-m4                  noarch          1.7.3-10.el9          baseos           14 k
 pkgconf-pkg-config          x86_64          1.7.3-10.el9          baseos           10 k

Transaction Summary
=========================================================================================
Install  5 Packages

Total download size: 390 k
Installed size: 1.2 M
Downloading Packages:
(1/5): pkgconf-1.7.3-10.el9.x86_64.rpm                    93 kB/s |  40 kB     00:00    
(2/5): libpkgconf-1.7.3-10.el9.x86_64.rpm                 74 kB/s |  35 kB     00:00    
(3/5): bash-completion-2.11-5.el9.noarch.rpm             281 kB/s | 291 kB     00:01    
(4/5): pkgconf-m4-1.7.3-10.el9.noarch.rpm                 20 kB/s |  14 kB     00:00    
(5/5): pkgconf-pkg-config-1.7.3-10.el9.x86_64.rpm         15 kB/s |  10 kB     00:00    
-----------------------------------------------------------------------------------------
Total                                                    337 kB/s | 390 kB     00:01     
Running transaction check
Transaction check succeeded.
Running transaction test
Transaction test succeeded.
Running transaction
  Preparing        :                                                                 1/1 
  Installing       : pkgconf-m4-1.7.3-10.el9.noarch                                  1/5 
  Installing       : libpkgconf-1.7.3-10.el9.x86_64                                  2/5 
  Installing       : pkgconf-1.7.3-10.el9.x86_64                                     3/5 
  Installing       : pkgconf-pkg-config-1.7.3-10.el9.x86_64                          4/5 
  Installing       : bash-completion-1:2.11-5.el9.noarch                             5/5 
  Running scriptlet: bash-completion-1:2.11-5.el9.noarch                             5/5 
  Verifying        : bash-completion-1:2.11-5.el9.noarch                             1/5 
  Verifying        : pkgconf-1.7.3-10.el9.x86_64                                     2/5 
  Verifying        : libpkgconf-1.7.3-10.el9.x86_64                                  3/5 
  Verifying        : pkgconf-m4-1.7.3-10.el9.noarch                                  4/5 
  Verifying        : pkgconf-pkg-config-1.7.3-10.el9.x86_64                          5/5 

Installed:
  bash-completion-1:2.11-5.el9.noarch             libpkgconf-1.7.3-10.el9.x86_64         
  pkgconf-1.7.3-10.el9.x86_64                     pkgconf-m4-1.7.3-10.el9.noarch         
  pkgconf-pkg-config-1.7.3-10.el9.x86_64         

Complete!
[root@k8s-master01 19]# cd ~
[root@k8s-master01 ~]# vim .bashrc
```
åœ¨`bashrc`æ–‡ä»¶ä¸­æ·»åŠ 

```bash
source <(kubectl completion bash)
```

ç„¶åé€€å‡ºç»ˆç«¯ï¼Œé‡æ–°è¿æ¥ä¸€ä¸‹

```bash
[root@k8s-master01 ~]# kubectl ge
```

æŒ‰tabï¼Œå‘ç°è‡ªåŠ¨è¡¥å…¨


```bash
[root@k8s-master01 ~]# kubectl get 
```

æŒ‰tab tab,ä¼šå‡ºç°

```bash
apiservices.apiregistration.k8s.io
bgpconfigurations.crd.projectcalico.org
bgpfilters.crd.projectcalico.org
bgppeers.crd.projectcalico.org
blockaffinities.crd.projectcalico.org
caliconodestatuses.crd.projectcalico.org
certificatesigningrequests.certificates.k8s.io
clusterinformations.crd.projectcalico.org
clusterrolebindings.rbac.authorization.k8s.io
clusterroles.rbac.authorization.k8s.io
componentstatuses
configmaps
controllerrevisions.apps
cronjobs.batch
csidrivers.storage.k8s.io
csinodes.storage.k8s.io
csistoragecapacities.storage.k8s.io
customresourcedefinitions.apiextensions.k8s.io
daemonsets.apps
deployments.apps
endpoints
endpointslices.discovery.k8s.io
events
events.events.k8s.io
felixconfigurations.crd.projectcalico.org
flowschemas.flowcontrol.apiserver.k8s.io
globalnetworkpolicies.crd.projectcalico.org
globalnetworksets.crd.projectcalico.org
horizontalpodautoscalers.autoscaling
hostendpoints.crd.projectcalico.org
ingressclasses.networking.k8s.io
ingresses.networking.k8s.io
ipamblocks.crd.projectcalico.org
ipamconfigs.crd.projectcalico.org
ipamhandles.crd.projectcalico.org
ippools.crd.projectcalico.org
ipreservations.crd.projectcalico.org
jobs.batch
kubecontrollersconfigurations.crd.projectcalico.org
[root@k8s-master01 ~]# kubectl get 
apiservices.apiregistration.k8s.io
bgpconfigurations.crd.projectcalico.org
bgpfilters.crd.projectcalico.org
bgppeers.crd.projectcalico.org
blockaffinities.crd.projectcalico.org
caliconodestatuses.crd.projectcalico.org
certificatesigningrequests.certificates.k8s.io
clusterinformations.crd.projectcalico.org
clusterrolebindings.rbac.authorization.k8s.io
clusterroles.rbac.authorization.k8s.io
componentstatuses
configmaps
controllerrevisions.apps
cronjobs.batch
csidrivers.storage.k8s.io
csinodes.storage.k8s.io
csistoragecapacities.storage.k8s.io
customresourcedefinitions.apiextensions.k8s.io
daemonsets.apps
deployments.apps
endpoints
endpointslices.discovery.k8s.io
events
events.events.k8s.io
felixconfigurations.crd.projectcalico.org
flowschemas.flowcontrol.apiserver.k8s.io
globalnetworkpolicies.crd.projectcalico.org
globalnetworksets.crd.projectcalico.org
horizontalpodautoscalers.autoscaling
hostendpoints.crd.projectcalico.org
ingressclasses.networking.k8s.io
ingresses.networking.k8s.io
ipamblocks.crd.projectcalico.org
ipamconfigs.crd.projectcalico.org
ipamhandles.crd.projectcalico.org
ippools.crd.projectcalico.org
ipreservations.crd.projectcalico.org
jobs.batch
kubecontrollersconfigurations.crd.projectcalico.org
```

`q`é€€å‡º










